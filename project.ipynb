{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h1> Mortality Predictions in ICU using ANN </h1>** \n",
    "\n",
    "Patients in the intensive care unit (ICU) face severe illness or injury and have a heightened risk of mortality. ICU mortality rates vary significantly based on the specific underlying condition, ranging from 1 in 20 for those admitted after planned surgeries to 1 in 4 for individuals with respiratory ailments. Assessing the likelihood of death involves evaluating the severity of a patient's illness through key physiological, clinical, and demographic factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle table-like data and matrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix,classification_report, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "%matplotlib inline\n",
    "sb.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Age</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>DiasABP</th>\n",
       "      <th>...</th>\n",
       "      <th>RespRate</th>\n",
       "      <th>SaO2</th>\n",
       "      <th>SysABP</th>\n",
       "      <th>Temp</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>Urine</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Weight</th>\n",
       "      <th>pH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.00</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>54</td>\n",
       "      <td>2.973333</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>58.795833</td>\n",
       "      <td>...</td>\n",
       "      <td>17.428571</td>\n",
       "      <td>97.250000</td>\n",
       "      <td>116.891892</td>\n",
       "      <td>37.357143</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.140</td>\n",
       "      <td>171.052632</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>80.060976</td>\n",
       "      <td>7.387273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.00</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>76</td>\n",
       "      <td>2.973333</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>58.897059</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>96.833333</td>\n",
       "      <td>113.411765</td>\n",
       "      <td>36.939130</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.140</td>\n",
       "      <td>151.560976</td>\n",
       "      <td>11.266667</td>\n",
       "      <td>80.670588</td>\n",
       "      <td>7.395000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.0</td>\n",
       "      <td>83.00</td>\n",
       "      <td>199.500000</td>\n",
       "      <td>44</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>67.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>125.687500</td>\n",
       "      <td>37.800000</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.140</td>\n",
       "      <td>124.951219</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>56.700000</td>\n",
       "      <td>7.495000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105.0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>68</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>17.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>58.795833</td>\n",
       "      <td>...</td>\n",
       "      <td>15.457627</td>\n",
       "      <td>97.250000</td>\n",
       "      <td>116.891892</td>\n",
       "      <td>36.223077</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.140</td>\n",
       "      <td>545.833333</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>84.600000</td>\n",
       "      <td>7.387273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.00</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>88</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>58.795833</td>\n",
       "      <td>...</td>\n",
       "      <td>19.166667</td>\n",
       "      <td>97.250000</td>\n",
       "      <td>116.891892</td>\n",
       "      <td>36.880000</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.140</td>\n",
       "      <td>62.131579</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>80.060976</td>\n",
       "      <td>7.387273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>82.0</td>\n",
       "      <td>32.25</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>70</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>68.865385</td>\n",
       "      <td>...</td>\n",
       "      <td>19.290323</td>\n",
       "      <td>97.230769</td>\n",
       "      <td>117.230769</td>\n",
       "      <td>37.004762</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.125</td>\n",
       "      <td>50.769231</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>7.381429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>82.0</td>\n",
       "      <td>32.25</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>58.754774</td>\n",
       "      <td>...</td>\n",
       "      <td>17.636364</td>\n",
       "      <td>97.230769</td>\n",
       "      <td>117.820733</td>\n",
       "      <td>36.580000</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.125</td>\n",
       "      <td>584.375000</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>166.400000</td>\n",
       "      <td>7.385000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>51.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>44</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>74.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>19.290323</td>\n",
       "      <td>97.230769</td>\n",
       "      <td>125.666667</td>\n",
       "      <td>37.792308</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.125</td>\n",
       "      <td>116.472222</td>\n",
       "      <td>11.066667</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>7.396667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>169.0</td>\n",
       "      <td>1971.00</td>\n",
       "      <td>1685.333333</td>\n",
       "      <td>37</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>89.250000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>145.0</td>\n",
       "      <td>9.650000</td>\n",
       "      <td>92.923077</td>\n",
       "      <td>...</td>\n",
       "      <td>19.290323</td>\n",
       "      <td>97.230769</td>\n",
       "      <td>166.615385</td>\n",
       "      <td>38.418182</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.125</td>\n",
       "      <td>11.230769</td>\n",
       "      <td>13.025000</td>\n",
       "      <td>87.400000</td>\n",
       "      <td>7.416000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>44.0</td>\n",
       "      <td>18.50</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>78</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>20.166667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1.116667</td>\n",
       "      <td>57.836957</td>\n",
       "      <td>...</td>\n",
       "      <td>19.290323</td>\n",
       "      <td>97.466667</td>\n",
       "      <td>111.532609</td>\n",
       "      <td>36.381395</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.125</td>\n",
       "      <td>57.750000</td>\n",
       "      <td>9.228571</td>\n",
       "      <td>87.838889</td>\n",
       "      <td>7.305600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3999 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ALP      ALT          AST  Age   Albumin        BUN  Bilirubin  \\\n",
       "0      77.0    31.00    46.000000   54  2.973333  10.500000   0.700000   \n",
       "1      77.0    31.00    46.000000   76  2.973333  18.333333   0.700000   \n",
       "2     116.0    83.00   199.500000   44  2.500000   4.666667   2.900000   \n",
       "3     105.0    12.00    15.000000   68  4.400000  17.666667   0.200000   \n",
       "4      77.0    31.00    46.000000   88  3.300000  35.000000   0.700000   \n",
       "...     ...      ...          ...  ...       ...        ...        ...   \n",
       "3994   82.0    32.25    49.000000   70  3.000000  16.000000   0.700000   \n",
       "3995   82.0    32.25    49.000000   25  3.000000   4.400000   0.700000   \n",
       "3996   51.0    20.00    20.000000   44  3.000000   7.750000   0.500000   \n",
       "3997  169.0  1971.00  1685.333333   37  3.100000  89.250000   0.733333   \n",
       "3998   44.0    18.50   126.000000   78  2.200000  20.166667   0.600000   \n",
       "\n",
       "      Cholesterol  Creatinine    DiasABP  ...   RespRate       SaO2  \\\n",
       "0           154.0    0.750000  58.795833  ...  17.428571  97.250000   \n",
       "1           154.0    1.100000  58.897059  ...  19.000000  96.833333   \n",
       "2           154.0    0.333333  67.125000  ...  19.000000  95.000000   \n",
       "3           154.0    0.766667  58.795833  ...  15.457627  97.250000   \n",
       "4           154.0    1.000000  58.795833  ...  19.166667  97.250000   \n",
       "...           ...         ...        ...  ...        ...        ...   \n",
       "3994        145.0    0.900000  68.865385  ...  19.290323  97.230769   \n",
       "3995        117.0    0.840000  58.754774  ...  17.636364  97.230769   \n",
       "3996        145.0    1.125000  74.166667  ...  19.290323  97.230769   \n",
       "3997        145.0    9.650000  92.923077  ...  19.290323  97.230769   \n",
       "3998        145.0    1.116667  57.836957  ...  19.290323  97.466667   \n",
       "\n",
       "          SysABP       Temp  TroponinI  TroponinT       Urine        WBC  \\\n",
       "0     116.891892  37.357143        2.1      0.140  171.052632  10.300000   \n",
       "1     113.411765  36.939130        2.1      0.140  151.560976  11.266667   \n",
       "2     125.687500  37.800000        2.1      0.140  124.951219   4.700000   \n",
       "3     116.891892  36.223077        2.1      0.140  545.833333   9.400000   \n",
       "4     116.891892  36.880000        2.1      0.140   62.131579   4.300000   \n",
       "...          ...        ...        ...        ...         ...        ...   \n",
       "3994  117.230769  37.004762        2.2      0.125   50.769231  14.500000   \n",
       "3995  117.820733  36.580000        2.2      0.125  584.375000   4.733333   \n",
       "3996  125.666667  37.792308        2.2      0.125  116.472222  11.066667   \n",
       "3997  166.615385  38.418182        2.2      0.125   11.230769  13.025000   \n",
       "3998  111.532609  36.381395        2.2      0.125   57.750000   9.228571   \n",
       "\n",
       "          Weight        pH  \n",
       "0      80.060976  7.387273  \n",
       "1      80.670588  7.395000  \n",
       "2      56.700000  7.495000  \n",
       "3      84.600000  7.387273  \n",
       "4      80.060976  7.387273  \n",
       "...          ...       ...  \n",
       "3994   87.000000  7.381429  \n",
       "3995  166.400000  7.385000  \n",
       "3996  109.000000  7.396667  \n",
       "3997   87.400000  7.416000  \n",
       "3998   87.838889  7.305600  \n",
       "\n",
       "[3999 rows x 42 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv',encoding='utf-8')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>In-hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3999 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      In-hospital_death\n",
       "0                     0\n",
       "1                     0\n",
       "2                     0\n",
       "3                     0\n",
       "4                     0\n",
       "...                 ...\n",
       "3994                  0\n",
       "3995                  0\n",
       "3996                  0\n",
       "3997                  1\n",
       "3998                  0\n",
       "\n",
       "[3999 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv('labels.csv',encoding = 'utf-8')\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3999 entries, 0 to 3998\n",
      "Data columns (total 42 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   ALP          3999 non-null   float64\n",
      " 1   ALT          3999 non-null   float64\n",
      " 2   AST          3999 non-null   float64\n",
      " 3   Age          3999 non-null   int64  \n",
      " 4   Albumin      3999 non-null   float64\n",
      " 5   BUN          3999 non-null   float64\n",
      " 6   Bilirubin    3999 non-null   float64\n",
      " 7   Cholesterol  3999 non-null   float64\n",
      " 8   Creatinine   3999 non-null   float64\n",
      " 9   DiasABP      3999 non-null   float64\n",
      " 10  FiO2         3999 non-null   float64\n",
      " 11  GCS          3999 non-null   float64\n",
      " 12  Gender       3999 non-null   int64  \n",
      " 13  Glucose      3999 non-null   float64\n",
      " 14  HCO3         3999 non-null   float64\n",
      " 15  HCT          3999 non-null   float64\n",
      " 16  HR           3999 non-null   float64\n",
      " 17  Height       3999 non-null   float64\n",
      " 18  ICUType      3999 non-null   int64  \n",
      " 19  K            3999 non-null   float64\n",
      " 20  Lactate      3999 non-null   float64\n",
      " 21  MAP          3999 non-null   float64\n",
      " 22  MechVent     3999 non-null   int64  \n",
      " 23  Mg           3999 non-null   float64\n",
      " 24  NIDiasABP    3999 non-null   float64\n",
      " 25  NIMAP        3999 non-null   float64\n",
      " 26  NISysABP     3999 non-null   float64\n",
      " 27  Na           3999 non-null   float64\n",
      " 28  PaCO2        3999 non-null   float64\n",
      " 29  PaO2         3999 non-null   float64\n",
      " 30  Platelets    3999 non-null   float64\n",
      " 31  RecordID     3999 non-null   float64\n",
      " 32  RespRate     3999 non-null   float64\n",
      " 33  SaO2         3999 non-null   float64\n",
      " 34  SysABP       3999 non-null   float64\n",
      " 35  Temp         3999 non-null   float64\n",
      " 36  TroponinI    3999 non-null   float64\n",
      " 37  TroponinT    3999 non-null   float64\n",
      " 38  Urine        3999 non-null   float64\n",
      " 39  WBC          3999 non-null   float64\n",
      " 40  Weight       3999 non-null   float64\n",
      " 41  pH           3999 non-null   float64\n",
      "dtypes: float64(38), int64(4)\n",
      "memory usage: 1.3 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3999 entries, 0 to 3998\n",
      "Data columns (total 1 columns):\n",
      " #   Column             Non-Null Count  Dtype\n",
      "---  ------             --------------  -----\n",
      " 0   In-hospital_death  3999 non-null   int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 31.4 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info(),labels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ALP            0\n",
       " ALT            0\n",
       " AST            0\n",
       " Age            0\n",
       " Albumin        0\n",
       " BUN            0\n",
       " Bilirubin      0\n",
       " Cholesterol    0\n",
       " Creatinine     0\n",
       " DiasABP        0\n",
       " FiO2           0\n",
       " GCS            0\n",
       " Gender         0\n",
       " Glucose        0\n",
       " HCO3           0\n",
       " HCT            0\n",
       " HR             0\n",
       " Height         0\n",
       " ICUType        0\n",
       " K              0\n",
       " Lactate        0\n",
       " MAP            0\n",
       " MechVent       0\n",
       " Mg             0\n",
       " NIDiasABP      0\n",
       " NIMAP          0\n",
       " NISysABP       0\n",
       " Na             0\n",
       " PaCO2          0\n",
       " PaO2           0\n",
       " Platelets      0\n",
       " RecordID       0\n",
       " RespRate       0\n",
       " SaO2           0\n",
       " SysABP         0\n",
       " Temp           0\n",
       " TroponinI      0\n",
       " TroponinT      0\n",
       " Urine          0\n",
       " WBC            0\n",
       " Weight         0\n",
       " pH             0\n",
       " dtype: int64,\n",
       " In-hospital_death    0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum(),labels.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data is cleaned no need to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALP',\n",
       " 'ALT',\n",
       " 'AST',\n",
       " 'Age',\n",
       " 'Albumin',\n",
       " 'BUN',\n",
       " 'Bilirubin',\n",
       " 'Cholesterol',\n",
       " 'Creatinine',\n",
       " 'DiasABP',\n",
       " 'FiO2',\n",
       " 'GCS',\n",
       " 'Gender',\n",
       " 'Glucose',\n",
       " 'HCO3',\n",
       " 'HCT',\n",
       " 'HR',\n",
       " 'Height',\n",
       " 'ICUType',\n",
       " 'K',\n",
       " 'Lactate',\n",
       " 'MAP',\n",
       " 'MechVent',\n",
       " 'Mg',\n",
       " 'NIDiasABP',\n",
       " 'NIMAP',\n",
       " 'NISysABP',\n",
       " 'Na',\n",
       " 'PaCO2',\n",
       " 'PaO2',\n",
       " 'Platelets',\n",
       " 'RecordID',\n",
       " 'RespRate',\n",
       " 'SaO2',\n",
       " 'SysABP',\n",
       " 'Temp',\n",
       " 'TroponinI',\n",
       " 'TroponinT',\n",
       " 'Urine',\n",
       " 'WBC',\n",
       " 'Weight',\n",
       " 'pH']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3999, 42), (3999, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape,labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Age</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>DiasABP</th>\n",
       "      <th>...</th>\n",
       "      <th>RespRate</th>\n",
       "      <th>SaO2</th>\n",
       "      <th>SysABP</th>\n",
       "      <th>Temp</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>Urine</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Weight</th>\n",
       "      <th>pH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>89.259978</td>\n",
       "      <td>91.709903</td>\n",
       "      <td>130.219258</td>\n",
       "      <td>64.247562</td>\n",
       "      <td>2.975942</td>\n",
       "      <td>25.449665</td>\n",
       "      <td>1.216527</td>\n",
       "      <td>152.403601</td>\n",
       "      <td>1.363130</td>\n",
       "      <td>59.262693</td>\n",
       "      <td>...</td>\n",
       "      <td>19.223967</td>\n",
       "      <td>96.940907</td>\n",
       "      <td>118.145550</td>\n",
       "      <td>36.956291</td>\n",
       "      <td>2.368702</td>\n",
       "      <td>0.337362</td>\n",
       "      <td>133.363074</td>\n",
       "      <td>12.521058</td>\n",
       "      <td>82.799384</td>\n",
       "      <td>7.488870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>70.397850</td>\n",
       "      <td>427.290858</td>\n",
       "      <td>590.482153</td>\n",
       "      <td>17.563142</td>\n",
       "      <td>0.404440</td>\n",
       "      <td>20.586576</td>\n",
       "      <td>2.961385</td>\n",
       "      <td>13.891279</td>\n",
       "      <td>1.406947</td>\n",
       "      <td>9.080069</td>\n",
       "      <td>...</td>\n",
       "      <td>2.074830</td>\n",
       "      <td>2.296143</td>\n",
       "      <td>16.540816</td>\n",
       "      <td>0.727382</td>\n",
       "      <td>2.418656</td>\n",
       "      <td>1.276145</td>\n",
       "      <td>117.304284</td>\n",
       "      <td>6.466063</td>\n",
       "      <td>23.117431</td>\n",
       "      <td>2.986373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.543478</td>\n",
       "      <td>38.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.644615</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>6.311667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>52.500000</td>\n",
       "      <td>2.973333</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>55.843712</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>97.230769</td>\n",
       "      <td>111.099359</td>\n",
       "      <td>36.614286</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>74.044118</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>68.201064</td>\n",
       "      <td>7.364142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>2.973333</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>58.795833</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>97.250000</td>\n",
       "      <td>116.891892</td>\n",
       "      <td>36.968750</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>111.032258</td>\n",
       "      <td>11.466667</td>\n",
       "      <td>80.060976</td>\n",
       "      <td>7.387273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>32.250000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>1.366667</td>\n",
       "      <td>62.210006</td>\n",
       "      <td>...</td>\n",
       "      <td>19.290323</td>\n",
       "      <td>97.250000</td>\n",
       "      <td>123.504098</td>\n",
       "      <td>37.364401</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>160.419207</td>\n",
       "      <td>14.950000</td>\n",
       "      <td>93.040476</td>\n",
       "      <td>7.407500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1472.333333</td>\n",
       "      <td>9143.428571</td>\n",
       "      <td>15680.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>170.833333</td>\n",
       "      <td>46.366667</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>16.457143</td>\n",
       "      <td>106.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>39.655172</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>181.725000</td>\n",
       "      <td>39.748980</td>\n",
       "      <td>49.200000</td>\n",
       "      <td>24.040000</td>\n",
       "      <td>3082.380952</td>\n",
       "      <td>137.233333</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>128.532500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ALP          ALT           AST          Age      Albumin  \\\n",
       "count  3999.000000  3999.000000   3999.000000  3999.000000  3999.000000   \n",
       "mean     89.259978    91.709903    130.219258    64.247562     2.975942   \n",
       "std      70.397850   427.290858    590.482153    17.563142     0.404440   \n",
       "min      12.000000     3.000000      6.000000    15.000000     1.100000   \n",
       "25%      77.000000    31.000000     46.000000    52.500000     2.973333   \n",
       "50%      77.000000    31.000000     46.000000    67.000000     2.973333   \n",
       "75%      82.000000    32.250000     49.000000    78.000000     3.000000   \n",
       "max    1472.333333  9143.428571  15680.000000    90.000000     5.300000   \n",
       "\n",
       "               BUN    Bilirubin  Cholesterol   Creatinine      DiasABP  ...  \\\n",
       "count  3999.000000  3999.000000  3999.000000  3999.000000  3999.000000  ...   \n",
       "mean     25.449665     1.216527   152.403601     1.363130    59.262693  ...   \n",
       "std      20.586576     2.961385    13.891279     1.406947     9.080069  ...   \n",
       "min       2.250000     0.100000     0.000000     0.200000     0.000000  ...   \n",
       "25%      13.000000     0.700000   154.000000     0.700000    55.843712  ...   \n",
       "50%      19.000000     0.700000   154.000000     0.933333    58.795833  ...   \n",
       "75%      30.000000     0.700000   154.000000     1.366667    62.210006  ...   \n",
       "max     170.833333    46.366667   330.000000    16.457143   106.666667  ...   \n",
       "\n",
       "          RespRate         SaO2       SysABP         Temp    TroponinI  \\\n",
       "count  3999.000000  3999.000000  3999.000000  3999.000000  3999.000000   \n",
       "mean     19.223967    96.940907   118.145550    36.956291     2.368702   \n",
       "std       2.074830     2.296143    16.540816     0.727382     2.418656   \n",
       "min      10.543478    38.800000     0.000000    21.644615     0.300000   \n",
       "25%      19.000000    97.230769   111.099359    36.614286     2.100000   \n",
       "50%      19.000000    97.250000   116.891892    36.968750     2.100000   \n",
       "75%      19.290323    97.250000   123.504098    37.364401     2.100000   \n",
       "max      39.655172   100.000000   181.725000    39.748980    49.200000   \n",
       "\n",
       "         TroponinT        Urine          WBC       Weight           pH  \n",
       "count  3999.000000  3999.000000  3999.000000  3999.000000  3999.000000  \n",
       "mean      0.337362   133.363074    12.521058    82.799384     7.488870  \n",
       "std       1.276145   117.304284     6.466063    23.117431     2.986373  \n",
       "min       0.010000     0.000000     0.100000     3.500000     6.311667  \n",
       "25%       0.125000    74.044118     8.900000    68.201064     7.364142  \n",
       "50%       0.140000   111.032258    11.466667    80.060976     7.387273  \n",
       "75%       0.140000   160.419207    14.950000    93.040476     7.407500  \n",
       "max      24.040000  3082.380952   137.233333   300.000000   128.532500  \n",
       "\n",
       "[8 rows x 42 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>In-hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.138535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.345503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       In-hospital_death\n",
       "count        3999.000000\n",
       "mean            0.138535\n",
       "std             0.345503\n",
       "min             0.000000\n",
       "25%             0.000000\n",
       "50%             0.000000\n",
       "75%             0.000000\n",
       "max             1.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Variable - Outcome\n",
    "0 - Alive\n",
    "\n",
    "1 - Death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3445\n",
       "1     554\n",
       "Name: In-hospital_death, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[\"In-hospital_death\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets do One Hot Encoding\n",
    "\n",
    "#### Benifits are - \n",
    "One-hot encoding is like giving each category its special code so a computer can understand and work with it better. Imagine you have three types of fruits: apples, bananas, and oranges. Instead of saying \"apple,\" \"banana,\" or \"orange,\" we assign a special code for each: 001 for apple, 010 for banana, and 100 for orange.\n",
    "\n",
    "Why is this helpful?\n",
    "\n",
    "1. **Simplicity for Computers**: Computers find it easier to work with numbers. With one-hot encoding, we convert categories into simple numbers (0s and 1s).\n",
    "\n",
    "2. **Avoiding Confusion**: We want to make sure the computer doesn't get confused into thinking apples (0, 0, 1) are like bananas (0, 1, 0) or oranges (1, 0, 0).\n",
    "\n",
    "3. **Equal Importance**: Each category gets its own unique code, showing that they are equally important and unrelated in terms of the task at hand.\n",
    "\n",
    "4. **Compatible with Algorithms**: Many machine learning algorithms need numerical data to train and make predictions. One-hot encoding allows us to use these algorithms with categorical data.\n",
    "\n",
    "In a nutshell, one-hot encoding helps the computer understand categories in a clear and organized way, making it easier for us to build models that learn and make accurate predictions based on these categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding\n",
    "one_hot_encoded_label = []\n",
    "for i in labels[\"In-hospital_death\"]:\n",
    "    if i == 0:\n",
    "        one_hot_encoded_label.append([1,0])\n",
    "    else:\n",
    "        one_hot_encoded_label.append([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  1  0\n",
       "1  1  0\n",
       "2  1  0\n",
       "3  1  0\n",
       "4  1  0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### To understand properly lets see the data\n",
    "one_hot_encoded_data = pd.DataFrame(one_hot_encoded_label)\n",
    "one_hot_encoded_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Age</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>DiasABP</th>\n",
       "      <th>...</th>\n",
       "      <th>SaO2</th>\n",
       "      <th>SysABP</th>\n",
       "      <th>Temp</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>Urine</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Weight</th>\n",
       "      <th>pH</th>\n",
       "      <th>In-hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>54</td>\n",
       "      <td>2.973333</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>58.795833</td>\n",
       "      <td>...</td>\n",
       "      <td>97.250000</td>\n",
       "      <td>116.891892</td>\n",
       "      <td>37.357143</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>171.052632</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>80.060976</td>\n",
       "      <td>7.387273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>76</td>\n",
       "      <td>2.973333</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>58.897059</td>\n",
       "      <td>...</td>\n",
       "      <td>96.833333</td>\n",
       "      <td>113.411765</td>\n",
       "      <td>36.939130</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>151.560976</td>\n",
       "      <td>11.266667</td>\n",
       "      <td>80.670588</td>\n",
       "      <td>7.395000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>199.5</td>\n",
       "      <td>44</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.9</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>67.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>125.687500</td>\n",
       "      <td>37.800000</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>124.951219</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>56.700000</td>\n",
       "      <td>7.495000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>68</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>17.666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>58.795833</td>\n",
       "      <td>...</td>\n",
       "      <td>97.250000</td>\n",
       "      <td>116.891892</td>\n",
       "      <td>36.223077</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>545.833333</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>84.600000</td>\n",
       "      <td>7.387273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>88</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>58.795833</td>\n",
       "      <td>...</td>\n",
       "      <td>97.250000</td>\n",
       "      <td>116.891892</td>\n",
       "      <td>36.880000</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>62.131579</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>80.060976</td>\n",
       "      <td>7.387273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ALP   ALT    AST  Age   Albumin        BUN  Bilirubin  Cholesterol  \\\n",
       "0   77.0  31.0   46.0   54  2.973333  10.500000        0.7        154.0   \n",
       "1   77.0  31.0   46.0   76  2.973333  18.333333        0.7        154.0   \n",
       "2  116.0  83.0  199.5   44  2.500000   4.666667        2.9        154.0   \n",
       "3  105.0  12.0   15.0   68  4.400000  17.666667        0.2        154.0   \n",
       "4   77.0  31.0   46.0   88  3.300000  35.000000        0.7        154.0   \n",
       "\n",
       "   Creatinine    DiasABP  ...       SaO2      SysABP       Temp  TroponinI  \\\n",
       "0    0.750000  58.795833  ...  97.250000  116.891892  37.357143        2.1   \n",
       "1    1.100000  58.897059  ...  96.833333  113.411765  36.939130        2.1   \n",
       "2    0.333333  67.125000  ...  95.000000  125.687500  37.800000        2.1   \n",
       "3    0.766667  58.795833  ...  97.250000  116.891892  36.223077        2.1   \n",
       "4    1.000000  58.795833  ...  97.250000  116.891892  36.880000        2.1   \n",
       "\n",
       "   TroponinT       Urine        WBC     Weight        pH  In-hospital_death  \n",
       "0       0.14  171.052632  10.300000  80.060976  7.387273                  0  \n",
       "1       0.14  151.560976  11.266667  80.670588  7.395000                  0  \n",
       "2       0.14  124.951219   4.700000  56.700000  7.495000                  0  \n",
       "3       0.14  545.833333   9.400000  84.600000  7.387273                  0  \n",
       "4       0.14   62.131579   4.300000  80.060976  7.387273                  0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets visualise it\n",
    "merged_data=pd.concat([data,labels],axis=1)\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Age</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>DiasABP</th>\n",
       "      <th>...</th>\n",
       "      <th>SaO2</th>\n",
       "      <th>SysABP</th>\n",
       "      <th>Temp</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>Urine</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Weight</th>\n",
       "      <th>pH</th>\n",
       "      <th>In-hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALP</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.114850</td>\n",
       "      <td>0.155750</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>-0.137771</td>\n",
       "      <td>0.155416</td>\n",
       "      <td>0.240297</td>\n",
       "      <td>-0.006795</td>\n",
       "      <td>0.131899</td>\n",
       "      <td>-0.035320</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024257</td>\n",
       "      <td>-0.052407</td>\n",
       "      <td>-0.051107</td>\n",
       "      <td>-0.011932</td>\n",
       "      <td>-0.019689</td>\n",
       "      <td>-0.040027</td>\n",
       "      <td>0.085952</td>\n",
       "      <td>-0.021914</td>\n",
       "      <td>-0.005073</td>\n",
       "      <td>0.115577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALT</th>\n",
       "      <td>0.114850</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.858741</td>\n",
       "      <td>-0.112012</td>\n",
       "      <td>-0.009850</td>\n",
       "      <td>0.038541</td>\n",
       "      <td>0.109332</td>\n",
       "      <td>-0.024351</td>\n",
       "      <td>0.077210</td>\n",
       "      <td>0.024430</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067018</td>\n",
       "      <td>-0.050335</td>\n",
       "      <td>-0.017507</td>\n",
       "      <td>-0.011350</td>\n",
       "      <td>0.037490</td>\n",
       "      <td>-0.048773</td>\n",
       "      <td>0.013325</td>\n",
       "      <td>-0.001541</td>\n",
       "      <td>-0.004561</td>\n",
       "      <td>0.070992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AST</th>\n",
       "      <td>0.155750</td>\n",
       "      <td>0.858741</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.088649</td>\n",
       "      <td>-0.037277</td>\n",
       "      <td>0.051244</td>\n",
       "      <td>0.127767</td>\n",
       "      <td>-0.020751</td>\n",
       "      <td>0.092024</td>\n",
       "      <td>0.030425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095091</td>\n",
       "      <td>-0.053931</td>\n",
       "      <td>-0.014374</td>\n",
       "      <td>-0.012664</td>\n",
       "      <td>0.081825</td>\n",
       "      <td>-0.064821</td>\n",
       "      <td>0.032749</td>\n",
       "      <td>0.008551</td>\n",
       "      <td>-0.001068</td>\n",
       "      <td>0.108484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.000879</td>\n",
       "      <td>-0.112012</td>\n",
       "      <td>-0.088649</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.036231</td>\n",
       "      <td>0.228768</td>\n",
       "      <td>-0.063837</td>\n",
       "      <td>-0.010103</td>\n",
       "      <td>0.033369</td>\n",
       "      <td>-0.263634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021496</td>\n",
       "      <td>0.009608</td>\n",
       "      <td>-0.146972</td>\n",
       "      <td>0.043898</td>\n",
       "      <td>0.051547</td>\n",
       "      <td>-0.255105</td>\n",
       "      <td>0.034414</td>\n",
       "      <td>-0.177945</td>\n",
       "      <td>0.025433</td>\n",
       "      <td>0.130701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albumin</th>\n",
       "      <td>-0.137771</td>\n",
       "      <td>-0.009850</td>\n",
       "      <td>-0.037277</td>\n",
       "      <td>-0.036231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.100987</td>\n",
       "      <td>-0.086068</td>\n",
       "      <td>0.058119</td>\n",
       "      <td>-0.030867</td>\n",
       "      <td>0.077583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035633</td>\n",
       "      <td>0.103017</td>\n",
       "      <td>0.006044</td>\n",
       "      <td>0.009577</td>\n",
       "      <td>0.039915</td>\n",
       "      <td>0.102044</td>\n",
       "      <td>-0.099285</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.007397</td>\n",
       "      <td>-0.126925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUN</th>\n",
       "      <td>0.155416</td>\n",
       "      <td>0.038541</td>\n",
       "      <td>0.051244</td>\n",
       "      <td>0.228768</td>\n",
       "      <td>-0.100987</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.185473</td>\n",
       "      <td>-0.014453</td>\n",
       "      <td>0.683278</td>\n",
       "      <td>-0.119703</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037919</td>\n",
       "      <td>-0.042018</td>\n",
       "      <td>-0.182530</td>\n",
       "      <td>0.072952</td>\n",
       "      <td>0.042128</td>\n",
       "      <td>-0.195167</td>\n",
       "      <td>0.101356</td>\n",
       "      <td>0.079346</td>\n",
       "      <td>-0.007620</td>\n",
       "      <td>0.223369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bilirubin</th>\n",
       "      <td>0.240297</td>\n",
       "      <td>0.109332</td>\n",
       "      <td>0.127767</td>\n",
       "      <td>-0.063837</td>\n",
       "      <td>-0.086068</td>\n",
       "      <td>0.185473</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.017119</td>\n",
       "      <td>0.140630</td>\n",
       "      <td>-0.031563</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003182</td>\n",
       "      <td>-0.053594</td>\n",
       "      <td>-0.091075</td>\n",
       "      <td>-0.007221</td>\n",
       "      <td>-0.016851</td>\n",
       "      <td>-0.076323</td>\n",
       "      <td>0.018515</td>\n",
       "      <td>0.033972</td>\n",
       "      <td>-0.006371</td>\n",
       "      <td>0.174017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cholesterol</th>\n",
       "      <td>-0.006795</td>\n",
       "      <td>-0.024351</td>\n",
       "      <td>-0.020751</td>\n",
       "      <td>-0.010103</td>\n",
       "      <td>0.058119</td>\n",
       "      <td>-0.014453</td>\n",
       "      <td>-0.017119</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.023809</td>\n",
       "      <td>0.072380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008578</td>\n",
       "      <td>0.011681</td>\n",
       "      <td>0.014865</td>\n",
       "      <td>-0.021201</td>\n",
       "      <td>0.036640</td>\n",
       "      <td>0.013926</td>\n",
       "      <td>-0.010553</td>\n",
       "      <td>-0.012247</td>\n",
       "      <td>-0.004304</td>\n",
       "      <td>-0.008578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Creatinine</th>\n",
       "      <td>0.131899</td>\n",
       "      <td>0.077210</td>\n",
       "      <td>0.092024</td>\n",
       "      <td>0.033369</td>\n",
       "      <td>-0.030867</td>\n",
       "      <td>0.683278</td>\n",
       "      <td>0.140630</td>\n",
       "      <td>-0.023809</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.072456</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019475</td>\n",
       "      <td>-0.030945</td>\n",
       "      <td>-0.108552</td>\n",
       "      <td>0.034726</td>\n",
       "      <td>0.047885</td>\n",
       "      <td>-0.162525</td>\n",
       "      <td>0.032108</td>\n",
       "      <td>0.091286</td>\n",
       "      <td>0.006364</td>\n",
       "      <td>0.117615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiasABP</th>\n",
       "      <td>-0.035320</td>\n",
       "      <td>0.024430</td>\n",
       "      <td>0.030425</td>\n",
       "      <td>-0.263634</td>\n",
       "      <td>0.077583</td>\n",
       "      <td>-0.119703</td>\n",
       "      <td>-0.031563</td>\n",
       "      <td>0.072380</td>\n",
       "      <td>-0.072456</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003486</td>\n",
       "      <td>0.594665</td>\n",
       "      <td>0.047105</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.119911</td>\n",
       "      <td>-0.019035</td>\n",
       "      <td>0.045176</td>\n",
       "      <td>-0.011028</td>\n",
       "      <td>-0.050506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FiO2</th>\n",
       "      <td>-0.003474</td>\n",
       "      <td>-0.003840</td>\n",
       "      <td>-0.003814</td>\n",
       "      <td>-0.011746</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>-0.009474</td>\n",
       "      <td>-0.004779</td>\n",
       "      <td>-0.299331</td>\n",
       "      <td>-0.008805</td>\n",
       "      <td>-0.169800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003533</td>\n",
       "      <td>-0.001053</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>-0.002287</td>\n",
       "      <td>-0.004453</td>\n",
       "      <td>-0.004723</td>\n",
       "      <td>-0.004137</td>\n",
       "      <td>-0.003293</td>\n",
       "      <td>-0.000945</td>\n",
       "      <td>-0.010986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GCS</th>\n",
       "      <td>0.020718</td>\n",
       "      <td>-0.073180</td>\n",
       "      <td>-0.123846</td>\n",
       "      <td>0.027736</td>\n",
       "      <td>0.144026</td>\n",
       "      <td>-0.031887</td>\n",
       "      <td>-0.042079</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>-0.021087</td>\n",
       "      <td>-0.052003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031215</td>\n",
       "      <td>-0.004390</td>\n",
       "      <td>-0.182994</td>\n",
       "      <td>-0.015576</td>\n",
       "      <td>-0.024584</td>\n",
       "      <td>0.160777</td>\n",
       "      <td>-0.107853</td>\n",
       "      <td>-0.052356</td>\n",
       "      <td>0.013951</td>\n",
       "      <td>-0.254104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>-0.002758</td>\n",
       "      <td>-0.002251</td>\n",
       "      <td>-0.002259</td>\n",
       "      <td>-0.020055</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>-0.004939</td>\n",
       "      <td>-0.002749</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>-0.004057</td>\n",
       "      <td>-0.059151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002127</td>\n",
       "      <td>-0.001196</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>-0.001756</td>\n",
       "      <td>-0.002442</td>\n",
       "      <td>-0.002989</td>\n",
       "      <td>-0.002588</td>\n",
       "      <td>-0.001816</td>\n",
       "      <td>-0.000540</td>\n",
       "      <td>-0.006346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glucose</th>\n",
       "      <td>0.014560</td>\n",
       "      <td>0.049459</td>\n",
       "      <td>0.076040</td>\n",
       "      <td>0.057239</td>\n",
       "      <td>0.030054</td>\n",
       "      <td>0.126179</td>\n",
       "      <td>-0.029639</td>\n",
       "      <td>0.039647</td>\n",
       "      <td>0.037075</td>\n",
       "      <td>0.009471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.035862</td>\n",
       "      <td>-0.033763</td>\n",
       "      <td>0.031719</td>\n",
       "      <td>0.043126</td>\n",
       "      <td>-0.020630</td>\n",
       "      <td>0.050115</td>\n",
       "      <td>0.066428</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>0.105764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HCO3</th>\n",
       "      <td>-0.095050</td>\n",
       "      <td>-0.088142</td>\n",
       "      <td>-0.117626</td>\n",
       "      <td>0.008126</td>\n",
       "      <td>0.182131</td>\n",
       "      <td>-0.236730</td>\n",
       "      <td>-0.132563</td>\n",
       "      <td>0.020805</td>\n",
       "      <td>-0.237834</td>\n",
       "      <td>0.029013</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048361</td>\n",
       "      <td>0.097960</td>\n",
       "      <td>0.064890</td>\n",
       "      <td>-0.021523</td>\n",
       "      <td>-0.045145</td>\n",
       "      <td>0.101372</td>\n",
       "      <td>-0.123303</td>\n",
       "      <td>0.075300</td>\n",
       "      <td>-0.016808</td>\n",
       "      <td>-0.129574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HCT</th>\n",
       "      <td>-0.010624</td>\n",
       "      <td>0.047127</td>\n",
       "      <td>0.022552</td>\n",
       "      <td>-0.065288</td>\n",
       "      <td>0.228917</td>\n",
       "      <td>-0.096426</td>\n",
       "      <td>-0.040429</td>\n",
       "      <td>0.074143</td>\n",
       "      <td>-0.057180</td>\n",
       "      <td>0.199300</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049210</td>\n",
       "      <td>0.071777</td>\n",
       "      <td>-0.032963</td>\n",
       "      <td>0.002804</td>\n",
       "      <td>0.078635</td>\n",
       "      <td>0.099207</td>\n",
       "      <td>0.044376</td>\n",
       "      <td>0.040221</td>\n",
       "      <td>0.001903</td>\n",
       "      <td>-0.009584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HR</th>\n",
       "      <td>0.026164</td>\n",
       "      <td>0.091215</td>\n",
       "      <td>0.104572</td>\n",
       "      <td>-0.246909</td>\n",
       "      <td>-0.137857</td>\n",
       "      <td>-0.060862</td>\n",
       "      <td>0.019632</td>\n",
       "      <td>-0.040332</td>\n",
       "      <td>-0.032015</td>\n",
       "      <td>0.136714</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042553</td>\n",
       "      <td>-0.152790</td>\n",
       "      <td>0.205528</td>\n",
       "      <td>-0.007784</td>\n",
       "      <td>-0.013808</td>\n",
       "      <td>-0.028292</td>\n",
       "      <td>0.114941</td>\n",
       "      <td>0.020675</td>\n",
       "      <td>0.014498</td>\n",
       "      <td>0.073561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Height</th>\n",
       "      <td>-0.014689</td>\n",
       "      <td>0.012009</td>\n",
       "      <td>0.016882</td>\n",
       "      <td>-0.088042</td>\n",
       "      <td>0.018550</td>\n",
       "      <td>0.023661</td>\n",
       "      <td>0.012634</td>\n",
       "      <td>0.006758</td>\n",
       "      <td>0.047051</td>\n",
       "      <td>0.046366</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018500</td>\n",
       "      <td>0.003668</td>\n",
       "      <td>0.020027</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.006398</td>\n",
       "      <td>0.025509</td>\n",
       "      <td>-0.006818</td>\n",
       "      <td>0.124226</td>\n",
       "      <td>-0.011014</td>\n",
       "      <td>-0.012456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ICUType</th>\n",
       "      <td>-0.002739</td>\n",
       "      <td>-0.002238</td>\n",
       "      <td>-0.002260</td>\n",
       "      <td>0.021302</td>\n",
       "      <td>-0.000138</td>\n",
       "      <td>-0.004988</td>\n",
       "      <td>-0.002727</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>-0.004856</td>\n",
       "      <td>-0.064856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>-0.001107</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>-0.001787</td>\n",
       "      <td>-0.002547</td>\n",
       "      <td>-0.003018</td>\n",
       "      <td>-0.002582</td>\n",
       "      <td>-0.001878</td>\n",
       "      <td>-0.000546</td>\n",
       "      <td>-0.006314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K</th>\n",
       "      <td>0.018410</td>\n",
       "      <td>-0.004501</td>\n",
       "      <td>0.031697</td>\n",
       "      <td>0.081105</td>\n",
       "      <td>-0.049365</td>\n",
       "      <td>0.264277</td>\n",
       "      <td>-0.020082</td>\n",
       "      <td>0.012194</td>\n",
       "      <td>0.285873</td>\n",
       "      <td>-0.108060</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038602</td>\n",
       "      <td>-0.104015</td>\n",
       "      <td>-0.068384</td>\n",
       "      <td>0.003915</td>\n",
       "      <td>0.013367</td>\n",
       "      <td>-0.109000</td>\n",
       "      <td>0.067543</td>\n",
       "      <td>0.145366</td>\n",
       "      <td>0.010682</td>\n",
       "      <td>0.018713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lactate</th>\n",
       "      <td>0.047983</td>\n",
       "      <td>0.193083</td>\n",
       "      <td>0.282596</td>\n",
       "      <td>-0.018507</td>\n",
       "      <td>-0.066734</td>\n",
       "      <td>0.037174</td>\n",
       "      <td>0.103735</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>0.047987</td>\n",
       "      <td>-0.041495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052907</td>\n",
       "      <td>-0.066719</td>\n",
       "      <td>-0.033017</td>\n",
       "      <td>-0.007629</td>\n",
       "      <td>0.019889</td>\n",
       "      <td>-0.038360</td>\n",
       "      <td>0.046109</td>\n",
       "      <td>0.014322</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.124184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP</th>\n",
       "      <td>-0.017456</td>\n",
       "      <td>0.021525</td>\n",
       "      <td>-0.000306</td>\n",
       "      <td>-0.114144</td>\n",
       "      <td>0.091947</td>\n",
       "      <td>-0.080205</td>\n",
       "      <td>-0.032284</td>\n",
       "      <td>0.027633</td>\n",
       "      <td>-0.054207</td>\n",
       "      <td>0.450196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026236</td>\n",
       "      <td>0.346110</td>\n",
       "      <td>0.034847</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>-0.020526</td>\n",
       "      <td>0.079936</td>\n",
       "      <td>-0.039635</td>\n",
       "      <td>0.023178</td>\n",
       "      <td>-0.003918</td>\n",
       "      <td>-0.022010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MechVent</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mg</th>\n",
       "      <td>0.047530</td>\n",
       "      <td>0.029570</td>\n",
       "      <td>0.042236</td>\n",
       "      <td>0.143433</td>\n",
       "      <td>0.028930</td>\n",
       "      <td>0.299111</td>\n",
       "      <td>0.128935</td>\n",
       "      <td>0.026229</td>\n",
       "      <td>0.158568</td>\n",
       "      <td>-0.068884</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014542</td>\n",
       "      <td>-0.048693</td>\n",
       "      <td>-0.104207</td>\n",
       "      <td>-0.001359</td>\n",
       "      <td>0.042362</td>\n",
       "      <td>-0.094634</td>\n",
       "      <td>0.064238</td>\n",
       "      <td>0.054599</td>\n",
       "      <td>-0.006743</td>\n",
       "      <td>0.061766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIDiasABP</th>\n",
       "      <td>-0.011555</td>\n",
       "      <td>0.023721</td>\n",
       "      <td>-0.000169</td>\n",
       "      <td>-0.264847</td>\n",
       "      <td>0.185396</td>\n",
       "      <td>-0.129948</td>\n",
       "      <td>-0.016910</td>\n",
       "      <td>0.022331</td>\n",
       "      <td>-0.027824</td>\n",
       "      <td>0.406921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009946</td>\n",
       "      <td>0.195174</td>\n",
       "      <td>0.030012</td>\n",
       "      <td>-0.012193</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.154416</td>\n",
       "      <td>-0.086380</td>\n",
       "      <td>0.004604</td>\n",
       "      <td>-0.023172</td>\n",
       "      <td>-0.080454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIMAP</th>\n",
       "      <td>-0.031432</td>\n",
       "      <td>0.011535</td>\n",
       "      <td>-0.018653</td>\n",
       "      <td>-0.182128</td>\n",
       "      <td>0.199239</td>\n",
       "      <td>-0.117328</td>\n",
       "      <td>-0.043218</td>\n",
       "      <td>0.016719</td>\n",
       "      <td>-0.008492</td>\n",
       "      <td>0.363677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033713</td>\n",
       "      <td>0.338897</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>-0.001113</td>\n",
       "      <td>-0.036129</td>\n",
       "      <td>0.141657</td>\n",
       "      <td>-0.080380</td>\n",
       "      <td>-0.001990</td>\n",
       "      <td>-0.016219</td>\n",
       "      <td>-0.078995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NISysABP</th>\n",
       "      <td>-0.041680</td>\n",
       "      <td>-0.006403</td>\n",
       "      <td>-0.031567</td>\n",
       "      <td>-0.003619</td>\n",
       "      <td>0.172102</td>\n",
       "      <td>-0.039398</td>\n",
       "      <td>-0.046814</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>0.028857</td>\n",
       "      <td>0.182347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054372</td>\n",
       "      <td>0.398844</td>\n",
       "      <td>0.026189</td>\n",
       "      <td>-0.012545</td>\n",
       "      <td>-0.074585</td>\n",
       "      <td>0.056194</td>\n",
       "      <td>-0.056883</td>\n",
       "      <td>-0.018760</td>\n",
       "      <td>-0.004546</td>\n",
       "      <td>-0.052866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Na</th>\n",
       "      <td>-0.033741</td>\n",
       "      <td>0.021272</td>\n",
       "      <td>0.021510</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>0.031793</td>\n",
       "      <td>0.033020</td>\n",
       "      <td>-0.075726</td>\n",
       "      <td>-0.020135</td>\n",
       "      <td>-0.050621</td>\n",
       "      <td>0.086441</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005721</td>\n",
       "      <td>0.086025</td>\n",
       "      <td>0.012596</td>\n",
       "      <td>-0.002000</td>\n",
       "      <td>-0.029598</td>\n",
       "      <td>0.019323</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>-0.035276</td>\n",
       "      <td>-0.023831</td>\n",
       "      <td>0.021979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PaCO2</th>\n",
       "      <td>-0.038665</td>\n",
       "      <td>-0.078684</td>\n",
       "      <td>-0.089867</td>\n",
       "      <td>-0.023488</td>\n",
       "      <td>0.075239</td>\n",
       "      <td>-0.057482</td>\n",
       "      <td>-0.099564</td>\n",
       "      <td>0.010901</td>\n",
       "      <td>-0.090957</td>\n",
       "      <td>0.001903</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130013</td>\n",
       "      <td>0.019603</td>\n",
       "      <td>0.026584</td>\n",
       "      <td>-0.023453</td>\n",
       "      <td>-0.046353</td>\n",
       "      <td>0.012166</td>\n",
       "      <td>-0.028493</td>\n",
       "      <td>0.147894</td>\n",
       "      <td>-0.004599</td>\n",
       "      <td>-0.075550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PaO2</th>\n",
       "      <td>-0.004341</td>\n",
       "      <td>-0.003155</td>\n",
       "      <td>-0.003046</td>\n",
       "      <td>-0.003788</td>\n",
       "      <td>0.001884</td>\n",
       "      <td>-0.006133</td>\n",
       "      <td>-0.004365</td>\n",
       "      <td>0.002261</td>\n",
       "      <td>-0.007304</td>\n",
       "      <td>-0.001624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>-0.001938</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>-0.002347</td>\n",
       "      <td>-0.002515</td>\n",
       "      <td>-0.002147</td>\n",
       "      <td>-0.003858</td>\n",
       "      <td>-0.003698</td>\n",
       "      <td>-0.000904</td>\n",
       "      <td>-0.008070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Platelets</th>\n",
       "      <td>0.071202</td>\n",
       "      <td>-0.077499</td>\n",
       "      <td>-0.084033</td>\n",
       "      <td>-0.023755</td>\n",
       "      <td>0.019028</td>\n",
       "      <td>-0.034506</td>\n",
       "      <td>-0.146147</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>-0.034072</td>\n",
       "      <td>0.026909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>-0.002860</td>\n",
       "      <td>-0.019080</td>\n",
       "      <td>0.009234</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.048811</td>\n",
       "      <td>0.254720</td>\n",
       "      <td>-0.032443</td>\n",
       "      <td>0.007590</td>\n",
       "      <td>-0.020178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecordID</th>\n",
       "      <td>0.013645</td>\n",
       "      <td>0.026546</td>\n",
       "      <td>0.018264</td>\n",
       "      <td>-0.019319</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>-0.033135</td>\n",
       "      <td>-0.022028</td>\n",
       "      <td>-0.175844</td>\n",
       "      <td>-0.027901</td>\n",
       "      <td>0.020986</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011660</td>\n",
       "      <td>0.027466</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>0.011042</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.043720</td>\n",
       "      <td>-0.005323</td>\n",
       "      <td>0.022967</td>\n",
       "      <td>0.031021</td>\n",
       "      <td>-0.011570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RespRate</th>\n",
       "      <td>-0.008747</td>\n",
       "      <td>0.019284</td>\n",
       "      <td>0.014621</td>\n",
       "      <td>0.069773</td>\n",
       "      <td>-0.024060</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>-0.017754</td>\n",
       "      <td>-0.009600</td>\n",
       "      <td>-0.013689</td>\n",
       "      <td>-0.002973</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043456</td>\n",
       "      <td>-0.029084</td>\n",
       "      <td>0.014763</td>\n",
       "      <td>0.013639</td>\n",
       "      <td>0.028234</td>\n",
       "      <td>-0.019015</td>\n",
       "      <td>0.066275</td>\n",
       "      <td>-0.043085</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.031718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SaO2</th>\n",
       "      <td>-0.024257</td>\n",
       "      <td>-0.067018</td>\n",
       "      <td>-0.095091</td>\n",
       "      <td>0.021496</td>\n",
       "      <td>0.035633</td>\n",
       "      <td>-0.037919</td>\n",
       "      <td>-0.003182</td>\n",
       "      <td>0.008578</td>\n",
       "      <td>-0.019475</td>\n",
       "      <td>-0.003486</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027539</td>\n",
       "      <td>0.045161</td>\n",
       "      <td>0.009874</td>\n",
       "      <td>-0.016704</td>\n",
       "      <td>0.047396</td>\n",
       "      <td>-0.027766</td>\n",
       "      <td>-0.042075</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>-0.056530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SysABP</th>\n",
       "      <td>-0.052407</td>\n",
       "      <td>-0.050335</td>\n",
       "      <td>-0.053931</td>\n",
       "      <td>0.009608</td>\n",
       "      <td>0.103017</td>\n",
       "      <td>-0.042018</td>\n",
       "      <td>-0.053594</td>\n",
       "      <td>0.011681</td>\n",
       "      <td>-0.030945</td>\n",
       "      <td>0.594665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023584</td>\n",
       "      <td>-0.001503</td>\n",
       "      <td>-0.095888</td>\n",
       "      <td>0.065891</td>\n",
       "      <td>-0.070584</td>\n",
       "      <td>-0.018837</td>\n",
       "      <td>-0.000909</td>\n",
       "      <td>-0.047688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp</th>\n",
       "      <td>-0.051107</td>\n",
       "      <td>-0.017507</td>\n",
       "      <td>-0.014374</td>\n",
       "      <td>-0.146972</td>\n",
       "      <td>0.006044</td>\n",
       "      <td>-0.182530</td>\n",
       "      <td>-0.091075</td>\n",
       "      <td>0.014865</td>\n",
       "      <td>-0.108552</td>\n",
       "      <td>0.047105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045161</td>\n",
       "      <td>0.023584</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005596</td>\n",
       "      <td>0.011998</td>\n",
       "      <td>0.020169</td>\n",
       "      <td>0.037632</td>\n",
       "      <td>0.086922</td>\n",
       "      <td>0.011210</td>\n",
       "      <td>-0.059519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TroponinI</th>\n",
       "      <td>-0.011932</td>\n",
       "      <td>-0.011350</td>\n",
       "      <td>-0.012664</td>\n",
       "      <td>0.043898</td>\n",
       "      <td>0.009577</td>\n",
       "      <td>0.072952</td>\n",
       "      <td>-0.007221</td>\n",
       "      <td>-0.021201</td>\n",
       "      <td>0.034726</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009874</td>\n",
       "      <td>-0.001503</td>\n",
       "      <td>-0.005596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.016389</td>\n",
       "      <td>-0.016438</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>-0.010348</td>\n",
       "      <td>-0.005872</td>\n",
       "      <td>0.053133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TroponinT</th>\n",
       "      <td>-0.019689</td>\n",
       "      <td>0.037490</td>\n",
       "      <td>0.081825</td>\n",
       "      <td>0.051547</td>\n",
       "      <td>0.039915</td>\n",
       "      <td>0.042128</td>\n",
       "      <td>-0.016851</td>\n",
       "      <td>0.036640</td>\n",
       "      <td>0.047885</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016704</td>\n",
       "      <td>-0.095888</td>\n",
       "      <td>0.011998</td>\n",
       "      <td>-0.016389</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.017428</td>\n",
       "      <td>0.033838</td>\n",
       "      <td>-0.027898</td>\n",
       "      <td>-0.006005</td>\n",
       "      <td>0.034866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Urine</th>\n",
       "      <td>-0.040027</td>\n",
       "      <td>-0.048773</td>\n",
       "      <td>-0.064821</td>\n",
       "      <td>-0.255105</td>\n",
       "      <td>0.102044</td>\n",
       "      <td>-0.195167</td>\n",
       "      <td>-0.076323</td>\n",
       "      <td>0.013926</td>\n",
       "      <td>-0.162525</td>\n",
       "      <td>0.119911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047396</td>\n",
       "      <td>0.065891</td>\n",
       "      <td>0.020169</td>\n",
       "      <td>-0.016438</td>\n",
       "      <td>-0.017428</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.101386</td>\n",
       "      <td>0.044751</td>\n",
       "      <td>-0.006337</td>\n",
       "      <td>-0.120881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WBC</th>\n",
       "      <td>0.085952</td>\n",
       "      <td>0.013325</td>\n",
       "      <td>0.032749</td>\n",
       "      <td>0.034414</td>\n",
       "      <td>-0.099285</td>\n",
       "      <td>0.101356</td>\n",
       "      <td>0.018515</td>\n",
       "      <td>-0.010553</td>\n",
       "      <td>0.032108</td>\n",
       "      <td>-0.019035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027766</td>\n",
       "      <td>-0.070584</td>\n",
       "      <td>0.037632</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.033838</td>\n",
       "      <td>-0.101386</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.040306</td>\n",
       "      <td>-0.002136</td>\n",
       "      <td>0.094936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td>-0.021914</td>\n",
       "      <td>-0.001541</td>\n",
       "      <td>0.008551</td>\n",
       "      <td>-0.177945</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.079346</td>\n",
       "      <td>0.033972</td>\n",
       "      <td>-0.012247</td>\n",
       "      <td>0.091286</td>\n",
       "      <td>0.045176</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042075</td>\n",
       "      <td>-0.018837</td>\n",
       "      <td>0.086922</td>\n",
       "      <td>-0.010348</td>\n",
       "      <td>-0.027898</td>\n",
       "      <td>0.044751</td>\n",
       "      <td>0.040306</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011871</td>\n",
       "      <td>-0.054443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pH</th>\n",
       "      <td>-0.005073</td>\n",
       "      <td>-0.004561</td>\n",
       "      <td>-0.001068</td>\n",
       "      <td>0.025433</td>\n",
       "      <td>0.007397</td>\n",
       "      <td>-0.007620</td>\n",
       "      <td>-0.006371</td>\n",
       "      <td>-0.004304</td>\n",
       "      <td>0.006364</td>\n",
       "      <td>-0.011028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>-0.000909</td>\n",
       "      <td>0.011210</td>\n",
       "      <td>-0.005872</td>\n",
       "      <td>-0.006005</td>\n",
       "      <td>-0.006337</td>\n",
       "      <td>-0.002136</td>\n",
       "      <td>-0.011871</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>In-hospital_death</th>\n",
       "      <td>0.115577</td>\n",
       "      <td>0.070992</td>\n",
       "      <td>0.108484</td>\n",
       "      <td>0.130701</td>\n",
       "      <td>-0.126925</td>\n",
       "      <td>0.223369</td>\n",
       "      <td>0.174017</td>\n",
       "      <td>-0.008578</td>\n",
       "      <td>0.117615</td>\n",
       "      <td>-0.050506</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056530</td>\n",
       "      <td>-0.047688</td>\n",
       "      <td>-0.059519</td>\n",
       "      <td>0.053133</td>\n",
       "      <td>0.034866</td>\n",
       "      <td>-0.120881</td>\n",
       "      <td>0.094936</td>\n",
       "      <td>-0.054443</td>\n",
       "      <td>0.024961</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ALP       ALT       AST       Age   Albumin       BUN  \\\n",
       "ALP                1.000000  0.114850  0.155750  0.000879 -0.137771  0.155416   \n",
       "ALT                0.114850  1.000000  0.858741 -0.112012 -0.009850  0.038541   \n",
       "AST                0.155750  0.858741  1.000000 -0.088649 -0.037277  0.051244   \n",
       "Age                0.000879 -0.112012 -0.088649  1.000000 -0.036231  0.228768   \n",
       "Albumin           -0.137771 -0.009850 -0.037277 -0.036231  1.000000 -0.100987   \n",
       "BUN                0.155416  0.038541  0.051244  0.228768 -0.100987  1.000000   \n",
       "Bilirubin          0.240297  0.109332  0.127767 -0.063837 -0.086068  0.185473   \n",
       "Cholesterol       -0.006795 -0.024351 -0.020751 -0.010103  0.058119 -0.014453   \n",
       "Creatinine         0.131899  0.077210  0.092024  0.033369 -0.030867  0.683278   \n",
       "DiasABP           -0.035320  0.024430  0.030425 -0.263634  0.077583 -0.119703   \n",
       "FiO2              -0.003474 -0.003840 -0.003814 -0.011746  0.001028 -0.009474   \n",
       "GCS                0.020718 -0.073180 -0.123846  0.027736  0.144026 -0.031887   \n",
       "Gender            -0.002758 -0.002251 -0.002259 -0.020055 -0.000094 -0.004939   \n",
       "Glucose            0.014560  0.049459  0.076040  0.057239  0.030054  0.126179   \n",
       "HCO3              -0.095050 -0.088142 -0.117626  0.008126  0.182131 -0.236730   \n",
       "HCT               -0.010624  0.047127  0.022552 -0.065288  0.228917 -0.096426   \n",
       "HR                 0.026164  0.091215  0.104572 -0.246909 -0.137857 -0.060862   \n",
       "Height            -0.014689  0.012009  0.016882 -0.088042  0.018550  0.023661   \n",
       "ICUType           -0.002739 -0.002238 -0.002260  0.021302 -0.000138 -0.004988   \n",
       "K                  0.018410 -0.004501  0.031697  0.081105 -0.049365  0.264277   \n",
       "Lactate            0.047983  0.193083  0.282596 -0.018507 -0.066734  0.037174   \n",
       "MAP               -0.017456  0.021525 -0.000306 -0.114144  0.091947 -0.080205   \n",
       "MechVent                NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Mg                 0.047530  0.029570  0.042236  0.143433  0.028930  0.299111   \n",
       "NIDiasABP         -0.011555  0.023721 -0.000169 -0.264847  0.185396 -0.129948   \n",
       "NIMAP             -0.031432  0.011535 -0.018653 -0.182128  0.199239 -0.117328   \n",
       "NISysABP          -0.041680 -0.006403 -0.031567 -0.003619  0.172102 -0.039398   \n",
       "Na                -0.033741  0.021272  0.021510  0.003085  0.031793  0.033020   \n",
       "PaCO2             -0.038665 -0.078684 -0.089867 -0.023488  0.075239 -0.057482   \n",
       "PaO2              -0.004341 -0.003155 -0.003046 -0.003788  0.001884 -0.006133   \n",
       "Platelets          0.071202 -0.077499 -0.084033 -0.023755  0.019028 -0.034506   \n",
       "RecordID           0.013645  0.026546  0.018264 -0.019319  0.019584 -0.033135   \n",
       "RespRate          -0.008747  0.019284  0.014621  0.069773 -0.024060  0.000831   \n",
       "SaO2              -0.024257 -0.067018 -0.095091  0.021496  0.035633 -0.037919   \n",
       "SysABP            -0.052407 -0.050335 -0.053931  0.009608  0.103017 -0.042018   \n",
       "Temp              -0.051107 -0.017507 -0.014374 -0.146972  0.006044 -0.182530   \n",
       "TroponinI         -0.011932 -0.011350 -0.012664  0.043898  0.009577  0.072952   \n",
       "TroponinT         -0.019689  0.037490  0.081825  0.051547  0.039915  0.042128   \n",
       "Urine             -0.040027 -0.048773 -0.064821 -0.255105  0.102044 -0.195167   \n",
       "WBC                0.085952  0.013325  0.032749  0.034414 -0.099285  0.101356   \n",
       "Weight            -0.021914 -0.001541  0.008551 -0.177945  0.000732  0.079346   \n",
       "pH                -0.005073 -0.004561 -0.001068  0.025433  0.007397 -0.007620   \n",
       "In-hospital_death  0.115577  0.070992  0.108484  0.130701 -0.126925  0.223369   \n",
       "\n",
       "                   Bilirubin  Cholesterol  Creatinine   DiasABP  ...  \\\n",
       "ALP                 0.240297    -0.006795    0.131899 -0.035320  ...   \n",
       "ALT                 0.109332    -0.024351    0.077210  0.024430  ...   \n",
       "AST                 0.127767    -0.020751    0.092024  0.030425  ...   \n",
       "Age                -0.063837    -0.010103    0.033369 -0.263634  ...   \n",
       "Albumin            -0.086068     0.058119   -0.030867  0.077583  ...   \n",
       "BUN                 0.185473    -0.014453    0.683278 -0.119703  ...   \n",
       "Bilirubin           1.000000    -0.017119    0.140630 -0.031563  ...   \n",
       "Cholesterol        -0.017119     1.000000   -0.023809  0.072380  ...   \n",
       "Creatinine          0.140630    -0.023809    1.000000 -0.072456  ...   \n",
       "DiasABP            -0.031563     0.072380   -0.072456  1.000000  ...   \n",
       "FiO2               -0.004779    -0.299331   -0.008805 -0.169800  ...   \n",
       "GCS                -0.042079     0.010350   -0.021087 -0.052003  ...   \n",
       "Gender             -0.002749     0.001810   -0.004057 -0.059151  ...   \n",
       "Glucose            -0.029639     0.039647    0.037075  0.009471  ...   \n",
       "HCO3               -0.132563     0.020805   -0.237834  0.029013  ...   \n",
       "HCT                -0.040429     0.074143   -0.057180  0.199300  ...   \n",
       "HR                  0.019632    -0.040332   -0.032015  0.136714  ...   \n",
       "Height              0.012634     0.006758    0.047051  0.046366  ...   \n",
       "ICUType            -0.002727     0.001792   -0.004856 -0.064856  ...   \n",
       "K                  -0.020082     0.012194    0.285873 -0.108060  ...   \n",
       "Lactate             0.103735     0.002234    0.047987 -0.041495  ...   \n",
       "MAP                -0.032284     0.027633   -0.054207  0.450196  ...   \n",
       "MechVent                 NaN          NaN         NaN       NaN  ...   \n",
       "Mg                  0.128935     0.026229    0.158568 -0.068884  ...   \n",
       "NIDiasABP          -0.016910     0.022331   -0.027824  0.406921  ...   \n",
       "NIMAP              -0.043218     0.016719   -0.008492  0.363677  ...   \n",
       "NISysABP           -0.046814     0.002373    0.028857  0.182347  ...   \n",
       "Na                 -0.075726    -0.020135   -0.050621  0.086441  ...   \n",
       "PaCO2              -0.099564     0.010901   -0.090957  0.001903  ...   \n",
       "PaO2               -0.004365     0.002261   -0.007304 -0.001624  ...   \n",
       "Platelets          -0.146147     0.003008   -0.034072  0.026909  ...   \n",
       "RecordID           -0.022028    -0.175844   -0.027901  0.020986  ...   \n",
       "RespRate           -0.017754    -0.009600   -0.013689 -0.002973  ...   \n",
       "SaO2               -0.003182     0.008578   -0.019475 -0.003486  ...   \n",
       "SysABP             -0.053594     0.011681   -0.030945  0.594665  ...   \n",
       "Temp               -0.091075     0.014865   -0.108552  0.047105  ...   \n",
       "TroponinI          -0.007221    -0.021201    0.034726  0.000694  ...   \n",
       "TroponinT          -0.016851     0.036640    0.047885  0.009634  ...   \n",
       "Urine              -0.076323     0.013926   -0.162525  0.119911  ...   \n",
       "WBC                 0.018515    -0.010553    0.032108 -0.019035  ...   \n",
       "Weight              0.033972    -0.012247    0.091286  0.045176  ...   \n",
       "pH                 -0.006371    -0.004304    0.006364 -0.011028  ...   \n",
       "In-hospital_death   0.174017    -0.008578    0.117615 -0.050506  ...   \n",
       "\n",
       "                       SaO2    SysABP      Temp  TroponinI  TroponinT  \\\n",
       "ALP               -0.024257 -0.052407 -0.051107  -0.011932  -0.019689   \n",
       "ALT               -0.067018 -0.050335 -0.017507  -0.011350   0.037490   \n",
       "AST               -0.095091 -0.053931 -0.014374  -0.012664   0.081825   \n",
       "Age                0.021496  0.009608 -0.146972   0.043898   0.051547   \n",
       "Albumin            0.035633  0.103017  0.006044   0.009577   0.039915   \n",
       "BUN               -0.037919 -0.042018 -0.182530   0.072952   0.042128   \n",
       "Bilirubin         -0.003182 -0.053594 -0.091075  -0.007221  -0.016851   \n",
       "Cholesterol        0.008578  0.011681  0.014865  -0.021201   0.036640   \n",
       "Creatinine        -0.019475 -0.030945 -0.108552   0.034726   0.047885   \n",
       "DiasABP           -0.003486  0.594665  0.047105   0.000694   0.009634   \n",
       "FiO2               0.003533 -0.001053  0.001465  -0.002287  -0.004453   \n",
       "GCS                0.031215 -0.004390 -0.182994  -0.015576  -0.024584   \n",
       "Gender             0.002127 -0.001196  0.000280  -0.001756  -0.002442   \n",
       "Glucose            0.002018  0.035862 -0.033763   0.031719   0.043126   \n",
       "HCO3              -0.048361  0.097960  0.064890  -0.021523  -0.045145   \n",
       "HCT               -0.049210  0.071777 -0.032963   0.002804   0.078635   \n",
       "HR                -0.042553 -0.152790  0.205528  -0.007784  -0.013808   \n",
       "Height            -0.018500  0.003668  0.020027   0.001599   0.006398   \n",
       "ICUType            0.002142 -0.001107  0.000304  -0.001787  -0.002547   \n",
       "K                 -0.038602 -0.104015 -0.068384   0.003915   0.013367   \n",
       "Lactate           -0.052907 -0.066719 -0.033017  -0.007629   0.019889   \n",
       "MAP                0.026236  0.346110  0.034847   0.001332  -0.020526   \n",
       "MechVent                NaN       NaN       NaN        NaN        NaN   \n",
       "Mg                -0.014542 -0.048693 -0.104207  -0.001359   0.042362   \n",
       "NIDiasABP          0.009946  0.195174  0.030012  -0.012193   0.000586   \n",
       "NIMAP              0.033713  0.338897  0.035853  -0.001113  -0.036129   \n",
       "NISysABP           0.054372  0.398844  0.026189  -0.012545  -0.074585   \n",
       "Na                -0.005721  0.086025  0.012596  -0.002000  -0.029598   \n",
       "PaCO2             -0.130013  0.019603  0.026584  -0.023453  -0.046353   \n",
       "PaO2               0.007321 -0.001938  0.000470  -0.002347  -0.002515   \n",
       "Platelets          0.011900 -0.002860 -0.019080   0.009234   0.001186   \n",
       "RecordID          -0.011660  0.027466  0.028300   0.011042   0.002464   \n",
       "RespRate          -0.043456 -0.029084  0.014763   0.013639   0.028234   \n",
       "SaO2               1.000000  0.027539  0.045161   0.009874  -0.016704   \n",
       "SysABP             0.027539  1.000000  0.023584  -0.001503  -0.095888   \n",
       "Temp               0.045161  0.023584  1.000000  -0.005596   0.011998   \n",
       "TroponinI          0.009874 -0.001503 -0.005596   1.000000  -0.016389   \n",
       "TroponinT         -0.016704 -0.095888  0.011998  -0.016389   1.000000   \n",
       "Urine              0.047396  0.065891  0.020169  -0.016438  -0.017428   \n",
       "WBC               -0.027766 -0.070584  0.037632   0.001771   0.033838   \n",
       "Weight            -0.042075 -0.018837  0.086922  -0.010348  -0.027898   \n",
       "pH                 0.002558 -0.000909  0.011210  -0.005872  -0.006005   \n",
       "In-hospital_death -0.056530 -0.047688 -0.059519   0.053133   0.034866   \n",
       "\n",
       "                      Urine       WBC    Weight        pH  In-hospital_death  \n",
       "ALP               -0.040027  0.085952 -0.021914 -0.005073           0.115577  \n",
       "ALT               -0.048773  0.013325 -0.001541 -0.004561           0.070992  \n",
       "AST               -0.064821  0.032749  0.008551 -0.001068           0.108484  \n",
       "Age               -0.255105  0.034414 -0.177945  0.025433           0.130701  \n",
       "Albumin            0.102044 -0.099285  0.000732  0.007397          -0.126925  \n",
       "BUN               -0.195167  0.101356  0.079346 -0.007620           0.223369  \n",
       "Bilirubin         -0.076323  0.018515  0.033972 -0.006371           0.174017  \n",
       "Cholesterol        0.013926 -0.010553 -0.012247 -0.004304          -0.008578  \n",
       "Creatinine        -0.162525  0.032108  0.091286  0.006364           0.117615  \n",
       "DiasABP            0.119911 -0.019035  0.045176 -0.011028          -0.050506  \n",
       "FiO2              -0.004723 -0.004137 -0.003293 -0.000945          -0.010986  \n",
       "GCS                0.160777 -0.107853 -0.052356  0.013951          -0.254104  \n",
       "Gender            -0.002989 -0.002588 -0.001816 -0.000540          -0.006346  \n",
       "Glucose           -0.020630  0.050115  0.066428  0.001707           0.105764  \n",
       "HCO3               0.101372 -0.123303  0.075300 -0.016808          -0.129574  \n",
       "HCT                0.099207  0.044376  0.040221  0.001903          -0.009584  \n",
       "HR                -0.028292  0.114941  0.020675  0.014498           0.073561  \n",
       "Height             0.025509 -0.006818  0.124226 -0.011014          -0.012456  \n",
       "ICUType           -0.003018 -0.002582 -0.001878 -0.000546          -0.006314  \n",
       "K                 -0.109000  0.067543  0.145366  0.010682           0.018713  \n",
       "Lactate           -0.038360  0.046109  0.014322  0.000496           0.124184  \n",
       "MAP                0.079936 -0.039635  0.023178 -0.003918          -0.022010  \n",
       "MechVent                NaN       NaN       NaN       NaN                NaN  \n",
       "Mg                -0.094634  0.064238  0.054599 -0.006743           0.061766  \n",
       "NIDiasABP          0.154416 -0.086380  0.004604 -0.023172          -0.080454  \n",
       "NIMAP              0.141657 -0.080380 -0.001990 -0.016219          -0.078995  \n",
       "NISysABP           0.056194 -0.056883 -0.018760 -0.004546          -0.052866  \n",
       "Na                 0.019323  0.001532 -0.035276 -0.023831           0.021979  \n",
       "PaCO2              0.012166 -0.028493  0.147894 -0.004599          -0.075550  \n",
       "PaO2              -0.002147 -0.003858 -0.003698 -0.000904          -0.008070  \n",
       "Platelets          0.048811  0.254720 -0.032443  0.007590          -0.020178  \n",
       "RecordID           0.043720 -0.005323  0.022967  0.031021          -0.011570  \n",
       "RespRate          -0.019015  0.066275 -0.043085  0.001242           0.031718  \n",
       "SaO2               0.047396 -0.027766 -0.042075  0.002558          -0.056530  \n",
       "SysABP             0.065891 -0.070584 -0.018837 -0.000909          -0.047688  \n",
       "Temp               0.020169  0.037632  0.086922  0.011210          -0.059519  \n",
       "TroponinI         -0.016438  0.001771 -0.010348 -0.005872           0.053133  \n",
       "TroponinT         -0.017428  0.033838 -0.027898 -0.006005           0.034866  \n",
       "Urine              1.000000 -0.101386  0.044751 -0.006337          -0.120881  \n",
       "WBC               -0.101386  1.000000  0.040306 -0.002136           0.094936  \n",
       "Weight             0.044751  0.040306  1.000000 -0.011871          -0.054443  \n",
       "pH                -0.006337 -0.002136 -0.011871  1.000000           0.024961  \n",
       "In-hospital_death -0.120881  0.094936 -0.054443  0.024961           1.000000  \n",
       "\n",
       "[43 rows x 43 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = merged_data.corr()\n",
    "corr_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the parameters which are more preferable for training\n",
    "\n",
    "\n",
    "in correlation matrix we found whose value positive is more preferable so,we filter the parameter names in below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALP                  0.115577\n",
       "ALT                  0.070992\n",
       "AST                  0.108484\n",
       "Age                  0.130701\n",
       "BUN                  0.223369\n",
       "Bilirubin            0.174017\n",
       "Creatinine           0.117615\n",
       "Glucose              0.105764\n",
       "HR                   0.073561\n",
       "K                    0.018713\n",
       "Lactate              0.124184\n",
       "Mg                   0.061766\n",
       "Na                   0.021979\n",
       "RespRate             0.031718\n",
       "TroponinI            0.053133\n",
       "TroponinT            0.034866\n",
       "WBC                  0.094936\n",
       "pH                   0.024961\n",
       "In-hospital_death    1.000000\n",
       "Name: In-hospital_death, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_dead =corr_matrix['In-hospital_death']\n",
    "corr_dead[corr_dead>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALP                  0.115577\n",
       "ALT                  0.070992\n",
       "AST                  0.108484\n",
       "Age                  0.130701\n",
       "BUN                  0.223369\n",
       "Bilirubin            0.174017\n",
       "Creatinine           0.117615\n",
       "Glucose              0.105764\n",
       "HR                   0.073561\n",
       "K                    0.018713\n",
       "Lactate              0.124184\n",
       "Mg                   0.061766\n",
       "Na                   0.021979\n",
       "RespRate             0.031718\n",
       "TroponinI            0.053133\n",
       "TroponinT            0.034866\n",
       "WBC                  0.094936\n",
       "pH                   0.024961\n",
       "In-hospital_death    1.000000\n",
       "Name: In-hospital_death, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_dead[corr_dead>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALP                  0.115577\n",
       "ALT                  0.070992\n",
       "AST                  0.108484\n",
       "Age                  0.130701\n",
       "BUN                  0.223369\n",
       "Bilirubin            0.174017\n",
       "Creatinine           0.117615\n",
       "Glucose              0.105764\n",
       "HR                   0.073561\n",
       "K                    0.018713\n",
       "Lactate              0.124184\n",
       "Mg                   0.061766\n",
       "Na                   0.021979\n",
       "RespRate             0.031718\n",
       "TroponinI            0.053133\n",
       "TroponinT            0.034866\n",
       "WBC                  0.094936\n",
       "pH                   0.024961\n",
       "In-hospital_death    1.000000\n",
       "Name: In-hospital_death, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_dead[corr_dead>0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Age</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>HR</th>\n",
       "      <th>K</th>\n",
       "      <th>Lactate</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Na</th>\n",
       "      <th>RespRate</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>WBC</th>\n",
       "      <th>pH</th>\n",
       "      <th>In-hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>54</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>70.810811</td>\n",
       "      <td>4.20</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>136.500000</td>\n",
       "      <td>17.428571</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>7.387273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>76</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>125.500000</td>\n",
       "      <td>80.794118</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>11.266667</td>\n",
       "      <td>7.395000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>199.5</td>\n",
       "      <td>44</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>134.333333</td>\n",
       "      <td>83.759259</td>\n",
       "      <td>4.26</td>\n",
       "      <td>1.366667</td>\n",
       "      <td>1.720000</td>\n",
       "      <td>138.333333</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>7.495000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>68</td>\n",
       "      <td>17.666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>117.333333</td>\n",
       "      <td>70.983333</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>139.333333</td>\n",
       "      <td>15.457627</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>7.387273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>88</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.500000</td>\n",
       "      <td>74.958333</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>1.550000</td>\n",
       "      <td>139.500000</td>\n",
       "      <td>19.166667</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>7.387273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ALP   ALT    AST  Age        BUN  Bilirubin  Creatinine     Glucose  \\\n",
       "0   77.0  31.0   46.0   54  10.500000        0.7    0.750000  160.000000   \n",
       "1   77.0  31.0   46.0   76  18.333333        0.7    1.100000  125.500000   \n",
       "2  116.0  83.0  199.5   44   4.666667        2.9    0.333333  134.333333   \n",
       "3  105.0  12.0   15.0   68  17.666667        0.2    0.766667  117.333333   \n",
       "4   77.0  31.0   46.0   88  35.000000        0.7    1.000000  102.500000   \n",
       "\n",
       "          HR     K   Lactate        Mg          Na   RespRate  TroponinI  \\\n",
       "0  70.810811  4.20  1.900000  1.700000  136.500000  17.428571        2.1   \n",
       "1  80.794118  3.90  1.900000  2.300000  137.000000  19.000000        2.1   \n",
       "2  83.759259  4.26  1.366667  1.720000  138.333333  19.000000        2.1   \n",
       "3  70.983333  4.00  1.900000  2.033333  139.333333  15.457627        2.1   \n",
       "4  74.958333  4.32  1.900000  1.550000  139.500000  19.166667        2.1   \n",
       "\n",
       "   TroponinT        WBC        pH  In-hospital_death  \n",
       "0       0.14  10.300000  7.387273                  0  \n",
       "1       0.14  11.266667  7.395000                  0  \n",
       "2       0.14   4.700000  7.495000                  0  \n",
       "3       0.14   9.400000  7.387273                  0  \n",
       "4       0.14   4.300000  7.387273                  0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data=merged_data[corr_dead[corr_dead>0].index.to_list()]\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `StandardScaler` in scikit-learn is a tool used for standardizing features by removing the mean and scaling to unit variance. Let's break down the benefits of using `StandardScaler` in an easy-to-understand manner:\n",
    "\n",
    "1. **Mean Removal**: It centers the feature columns around zero by removing the mean. This is important because many machine learning algorithms assume that the features are centered around zero.\n",
    "\n",
    "2. **Unit Variance Scaling**: It scales the feature columns to have a standard deviation of 1. This is crucial because features with different scales might lead the machine learning algorithm to assign more weight to features with larger scales, potentially causing issues in the model's performance.\n",
    "\n",
    "   Imagine you have a feature like \"Income\" ranging from 20,000 to 200,000 and another feature like \"Age\" ranging from 0 to 100. Without scaling, the algorithm might give more importance to \"Income\" just because its values are larger, even if \"Age\" is equally important.\n",
    "\n",
    "3. **Makes Optimization Easier**: Many optimization algorithms (e.g., gradient descent) work faster and are more stable when features are on a similar scale. Scaling helps in reaching the optimal solution more quickly.\n",
    "\n",
    "4. **Maintains Relationships Between Features**: It ensures that the relative relationships (e.g., correlations) between features remain the same after scaling. Scaling doesn't change the relationships; it just puts them on a consistent scale.\n",
    "\n",
    "In summary, `StandardScaler` is a preprocessing step that helps in preparing the data for machine learning models, ensuring fair treatment of all features and facilitating a smoother optimization process during model training.\n",
    "\n",
    "\n",
    "In more easy manner-\n",
    "Of course! Imagine you have a bunch of different things to eat, like fruits and snacks. But these things come in different sizes and shapes. Some are big, some are small. It's like comparing apples and oranges, literally!\n",
    "\n",
    "Now, let's say you want to compare them in a fair way. You want to be able to say which one you like the most, not just because it's bigger or smaller, but because of its own taste. To do that, you need to make sure they're all in the same size.\n",
    "\n",
    "The StandardScaler is like a magical machine that takes these fruits and snacks and makes them all the same size, just like if you were comparing all fruits to be the same size as an apple. This way, when you say which one you like the most, it's based on taste, not size.\n",
    "\n",
    "In the world of computers and numbers (which is like a big playground for math), we have numbers that are like those fruits and snacks. They come in different sizes. StandardScaler helps us make them all the same size, so when we use them in a special math game called a machine learning game, they play fair and everyone gets a fair chance to show how important they are.\n",
    "\n",
    "So, it's like making sure all our fruits and snacks are the same size before we decide which one is the yummiest! 🍎🍊🍇🍪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_class = new_data[new_data['In-hospital_death'] == 0]\n",
    "minority_class = new_data[new_data['In-hospital_death'] == 1]\n",
    "\n",
    "# Upsample minority class\n",
    "minority_class_upsampled = resample(minority_class, replace=True, n_samples=len(majority_class), random_state=42)\n",
    "\n",
    "# Combine majority class with upsampled minority class\n",
    "balanced_data = pd.concat([majority_class, minority_class_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    554\n",
       "Name: In-hospital_death, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(minority_class),len(majority_class),len(minority_class_upsampled)\n",
    "minority_class_upsampled['In-hospital_death'].value_counts()\n",
    "balanced_data['In-hospital_death'].value_counts()\n",
    "minority_class['In-hospital_death'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = balanced_data.drop('In-hospital_death', axis=1)\n",
    "y = balanced_data['In-hospital_death']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: In-hospital_death, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Age</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>HR</th>\n",
       "      <th>K</th>\n",
       "      <th>Lactate</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Na</th>\n",
       "      <th>RespRate</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>WBC</th>\n",
       "      <th>pH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>54</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>70.810811</td>\n",
       "      <td>4.20</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>136.500000</td>\n",
       "      <td>17.428571</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>7.387273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>76</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>125.500000</td>\n",
       "      <td>80.794118</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>11.266667</td>\n",
       "      <td>7.395000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>199.5</td>\n",
       "      <td>44</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>134.333333</td>\n",
       "      <td>83.759259</td>\n",
       "      <td>4.26</td>\n",
       "      <td>1.366667</td>\n",
       "      <td>1.720000</td>\n",
       "      <td>138.333333</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>7.495000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>68</td>\n",
       "      <td>17.666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>117.333333</td>\n",
       "      <td>70.983333</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>139.333333</td>\n",
       "      <td>15.457627</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>7.387273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>88</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.500000</td>\n",
       "      <td>74.958333</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>1.550000</td>\n",
       "      <td>139.500000</td>\n",
       "      <td>19.166667</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>7.387273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ALP   ALT    AST  Age        BUN  Bilirubin  Creatinine     Glucose  \\\n",
       "0   77.0  31.0   46.0   54  10.500000        0.7    0.750000  160.000000   \n",
       "1   77.0  31.0   46.0   76  18.333333        0.7    1.100000  125.500000   \n",
       "2  116.0  83.0  199.5   44   4.666667        2.9    0.333333  134.333333   \n",
       "3  105.0  12.0   15.0   68  17.666667        0.2    0.766667  117.333333   \n",
       "4   77.0  31.0   46.0   88  35.000000        0.7    1.000000  102.500000   \n",
       "\n",
       "          HR     K   Lactate        Mg          Na   RespRate  TroponinI  \\\n",
       "0  70.810811  4.20  1.900000  1.700000  136.500000  17.428571        2.1   \n",
       "1  80.794118  3.90  1.900000  2.300000  137.000000  19.000000        2.1   \n",
       "2  83.759259  4.26  1.366667  1.720000  138.333333  19.000000        2.1   \n",
       "3  70.983333  4.00  1.900000  2.033333  139.333333  15.457627        2.1   \n",
       "4  74.958333  4.32  1.900000  1.550000  139.500000  19.166667        2.1   \n",
       "\n",
       "   TroponinT        WBC        pH  \n",
       "0       0.14  10.300000  7.387273  \n",
       "1       0.14  11.266667  7.395000  \n",
       "2       0.14   4.700000  7.495000  \n",
       "3       0.14   9.400000  7.387273  \n",
       "4       0.14   4.300000  7.387273  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 6890, 6890)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x.columns),len(x),len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc = StandardScaler()\n",
    "# transformed_data = sc.fit_transform(x)\n",
    "# transformed_data[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MinMaxScaler\n",
    "\n",
    "Sure, let's explain Min-Max Scaler in a simple way!\n",
    "\n",
    "Imagine you have a collection of toys, like toy cars and toy dolls. Each toy has a different height and width. Now, let's say you want to play with these toys in a dollhouse where the rooms are of a certain size.\n",
    "\n",
    "The Min-Max Scaler is like a magic machine that helps you resize your toys in a way that they all fit nicely into the rooms of the dollhouse. It adjusts the size of each toy, making sure they all fit comfortably.\n",
    "\n",
    "In the world of numbers and data (which is like a big puzzle), we have numbers that are like those toys with different sizes. Min-Max Scaler helps us resize these numbers so they all fit nicely in a specific range, like from 0 to 1.\n",
    "\n",
    "Why is this useful? Well, in some games or puzzles, we want all our numbers to be in a certain range so they can play nicely together, just like the toys fitting into the dollhouse rooms. Min-Max Scaler helps us achieve this fair play by resizing the numbers to fit within the desired range.\n",
    "\n",
    "So, it's like making sure our toys fit nicely in the dollhouse rooms, and Min-Max Scaler helps us do the same with our numbers! 🏠🚗🎎\n",
    "\n",
    "\n",
    "#### Technical-\n",
    "\n",
    "Absolutely! Let's delve a bit more into the technical details of Min-Max Scaler.\n",
    "\n",
    "Min-Max Scaler is a technique used in data preprocessing, specifically for feature scaling, in the field of machine learning and data analysis. Its purpose is to transform the features (columns) of a dataset so that they fall within a specified range, typically [0, 1]. The formula to achieve this scaling for each feature \\(X\\) is:\n",
    "\n",
    "\\[X_{\\text{scaled}} = \\frac{X - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}}\\]\n",
    "\n",
    "where:\n",
    "- \\(X\\) is an original value of a feature,\n",
    "- \\(X_{\\text{min}}\\) is the minimum value of that feature in the dataset,\n",
    "- \\(X_{\\text{max}}\\) is the maximum value of that feature in the dataset.\n",
    "\n",
    "Here's a breakdown:\n",
    "\n",
    "- It subtracts the minimum value (\\(X_{\\text{min}}\\)) of the feature from each value, so the minimum value becomes 0.\n",
    "- Then, it divides by the range of the feature (\\(X_{\\text{max}} - X_{\\text{min}}\\)), so the maximum value of the feature becomes 1.\n",
    "\n",
    "This transformation is particularly useful when you want to ensure that each feature contributes equally to the computation or analysis, especially in cases where the features have different units or scales. It's commonly applied to features that need to be on a similar scale, but not necessarily in a specific statistical distribution.\n",
    "\n",
    "In simpler terms, Min-Max Scaler helps in resizing the features so that they all fit nicely in a range, like making sure all your toys fit nicely in the dollhouse rooms (the desired range). This helps in fair comparisons and computations in machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "transformed_data = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.044510</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>0.002552</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.048937</td>\n",
       "      <td>0.012968</td>\n",
       "      <td>0.033831</td>\n",
       "      <td>0.265339</td>\n",
       "      <td>0.502890</td>\n",
       "      <td>0.125926</td>\n",
       "      <td>0.017730</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.471402</td>\n",
       "      <td>0.236506</td>\n",
       "      <td>0.03681</td>\n",
       "      <td>0.00541</td>\n",
       "      <td>0.074380</td>\n",
       "      <td>0.008801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.044510</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>0.002552</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.095403</td>\n",
       "      <td>0.012968</td>\n",
       "      <td>0.055360</td>\n",
       "      <td>0.182869</td>\n",
       "      <td>0.576927</td>\n",
       "      <td>0.103704</td>\n",
       "      <td>0.017730</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.480830</td>\n",
       "      <td>0.290485</td>\n",
       "      <td>0.03681</td>\n",
       "      <td>0.00541</td>\n",
       "      <td>0.081429</td>\n",
       "      <td>0.008864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.071217</td>\n",
       "      <td>0.008752</td>\n",
       "      <td>0.012345</td>\n",
       "      <td>0.386667</td>\n",
       "      <td>0.014335</td>\n",
       "      <td>0.060519</td>\n",
       "      <td>0.008202</td>\n",
       "      <td>0.203984</td>\n",
       "      <td>0.598917</td>\n",
       "      <td>0.130370</td>\n",
       "      <td>0.011426</td>\n",
       "      <td>0.106897</td>\n",
       "      <td>0.505971</td>\n",
       "      <td>0.290485</td>\n",
       "      <td>0.03681</td>\n",
       "      <td>0.00541</td>\n",
       "      <td>0.033544</td>\n",
       "      <td>0.009682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.063684</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>0.091448</td>\n",
       "      <td>0.002161</td>\n",
       "      <td>0.034856</td>\n",
       "      <td>0.163347</td>\n",
       "      <td>0.504170</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.017730</td>\n",
       "      <td>0.160920</td>\n",
       "      <td>0.524827</td>\n",
       "      <td>0.168803</td>\n",
       "      <td>0.03681</td>\n",
       "      <td>0.00541</td>\n",
       "      <td>0.067817</td>\n",
       "      <td>0.008801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.044510</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>0.002552</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.194266</td>\n",
       "      <td>0.012968</td>\n",
       "      <td>0.049209</td>\n",
       "      <td>0.127888</td>\n",
       "      <td>0.533649</td>\n",
       "      <td>0.134815</td>\n",
       "      <td>0.017730</td>\n",
       "      <td>0.077586</td>\n",
       "      <td>0.527970</td>\n",
       "      <td>0.296210</td>\n",
       "      <td>0.03681</td>\n",
       "      <td>0.00541</td>\n",
       "      <td>0.030627</td>\n",
       "      <td>0.008801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.044510  0.003063  0.002552  0.520000  0.048937  0.012968  0.033831   \n",
       "1  0.044510  0.003063  0.002552  0.813333  0.095403  0.012968  0.055360   \n",
       "2  0.071217  0.008752  0.012345  0.386667  0.014335  0.060519  0.008202   \n",
       "3  0.063684  0.000985  0.000574  0.706667  0.091448  0.002161  0.034856   \n",
       "4  0.044510  0.003063  0.002552  0.973333  0.194266  0.012968  0.049209   \n",
       "\n",
       "         7         8         9         10        11        12        13  \\\n",
       "0  0.265339  0.502890  0.125926  0.017730  0.103448  0.471402  0.236506   \n",
       "1  0.182869  0.576927  0.103704  0.017730  0.206897  0.480830  0.290485   \n",
       "2  0.203984  0.598917  0.130370  0.011426  0.106897  0.505971  0.290485   \n",
       "3  0.163347  0.504170  0.111111  0.017730  0.160920  0.524827  0.168803   \n",
       "4  0.127888  0.533649  0.134815  0.017730  0.077586  0.527970  0.296210   \n",
       "\n",
       "        14       15        16        17  \n",
       "0  0.03681  0.00541  0.074380  0.008801  \n",
       "1  0.03681  0.00541  0.081429  0.008864  \n",
       "2  0.03681  0.00541  0.033544  0.009682  \n",
       "3  0.03681  0.00541  0.067817  0.008801  \n",
       "4  0.03681  0.00541  0.030627  0.008801  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Just checking how our data looking in transformed way\n",
    "\n",
    "checking = pd.DataFrame(transformed_data)\n",
    "checking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6890, 18) (6890,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5512, 18) (1378, 18) (5512,) (1378,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building  Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put models in dicionary\n",
    "models = {\"Logistic Regression\": LogisticRegression(),\n",
    "          \n",
    "          \"Random Forest\": RandomForestClassifier(),\n",
    "          \"Gaussian Naive Bayes\":GaussianNB(),\n",
    "          \"SVM\":svm.SVC(kernel='linear'),\n",
    "          \"Gradient Boosting\":GradientBoostingClassifier()}\n",
    "\n",
    "# see for example here name = KNN and model =KNeighborsClassifier()\n",
    "\n",
    "# Create function to fit and score model\n",
    "def fit_and_score(models,X_train,X_test,y_train,y_test):\n",
    "    \"\"\"\n",
    "    Fits and evaluate given ml model\n",
    "    models: a dictionary of different scilit-learn machine learning models\n",
    "    x_train : training data\n",
    "    x_test : testing data\n",
    "    \"\"\"\n",
    "    # set up random seed\n",
    "    np.random.seed(42)\n",
    "    # Make a dicitionary to keep models\n",
    "    model_score = {}\n",
    "    # Loop through models\n",
    "    for name, model in models.items():\n",
    "        #Fit the model to data\n",
    "        model.fit(X_train,y_train)\n",
    "        # Evaluate the model and append its score to model_score\n",
    "        model_score[name]=model.score(X_test,y_test)\n",
    "    return model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': 0.6734397677793904,\n",
       " 'Random Forest': 0.9724238026124818,\n",
       " 'Gaussian Naive Bayes': 0.5899854862119013,\n",
       " 'SVM': 0.6705370101596516,\n",
       " 'Gradient Boosting': 0.7685050798258345}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score = fit_and_score(models,x_train,x_test,y_train,y_test)\n",
    "model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9702467343976778"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4]),\n",
       " [Text(0, 0, 'Logistic Regression'),\n",
       "  Text(1, 0, 'Random Forest'),\n",
       "  Text(2, 0, 'Gaussian Naive Bayes'),\n",
       "  Text(3, 0, 'SVM'),\n",
       "  Text(4, 0, 'Gradient Boosting')])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_compare=pd.DataFrame(model_score, index=[\"accuracy\"])\n",
    "# model_compare.plot.bar(); # give close bar to each other try it\n",
    "model_compare.T.plot.bar()\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will do following:\n",
    "\n",
    "-> Hyperparameter Tuning\n",
    "\n",
    "-> Feauture importance\n",
    "\n",
    "-> Confusion matrix\n",
    "\n",
    "-> Cross-Validation\n",
    "\n",
    "-> Precision\n",
    "\n",
    "-> Recall\n",
    "\n",
    "-> F1 score\n",
    "\n",
    "-> Classification report\n",
    "\n",
    "-> ROC curve\n",
    "\n",
    "-> Area under the curve(AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypertuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is GridSearchCV used for?\n",
    "\n",
    "Ans-> GridSearchCV (Grid Search Cross-Validation) is a technique used in machine learning to search and find the optimal combination of hyperparameters for a given model. It systematically explores a predefined set of hyperparameter values, creating a “grid” of possible combinations. It then evaluates each combination using cross-validation and selects the one that produces the best performance. GridSearchCV helps in automating the process of hyperparameter tuning, enhancing model performance, and avoiding manual trial-and-error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(random_state = 42)\n",
    "from pprint import pprint\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())\n",
    "Parameters currently in use:\n",
    "\n",
    "{'bootstrap': True,\n",
    "\n",
    " 'criterion': 'mse',\n",
    "\n",
    " 'max_depth': None,\n",
    " \n",
    " 'max_features': 'auto',\n",
    " \n",
    " 'max_leaf_nodes': None,\n",
    " \n",
    " 'min_impurity_decrease': 0.0,\n",
    " \n",
    " 'min_impurity_split': None,\n",
    " \n",
    " 'min_samples_leaf': 1,\n",
    " \n",
    " 'min_samples_split': 2,\n",
    " \n",
    " 'min_weight_fraction_leaf': 0.0,\n",
    " \n",
    " 'n_estimators': 10,\n",
    " \n",
    " 'n_jobs': 1,\n",
    " \n",
    " 'oob_score': False,\n",
    " \n",
    " 'random_state': 42,\n",
    " 'verbose': 0,\n",
    " \n",
    " 'warm_start': False}\n",
    "\n",
    "\n",
    "-> n_estimators = number of trees in the foreset\n",
    "\n",
    "-> max_features = max number of features considered for splitting a node\n",
    "\n",
    "-> max_depth = max number of levels in each decision tree\n",
    "\n",
    "-> min_samples_split = min number of data points placed in a node before the node is split\n",
    "\n",
    "-> min_samples_leaf = min number of data points allowed in a leaf node\n",
    "\n",
    "-> bootstrap = method for sampling data points (with or without replacement)\n",
    "\n",
    "\n",
    "### Example Code\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "\n",
    "##### Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "\n",
    "##### Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "\n",
    "##### Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "\n",
    "max_depth.append(None)\n",
    "##### Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "\n",
    "##### Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "\n",
    "##### Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "##### Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "\n",
    "               'max_features': max_features,\n",
    "               \n",
    "               'max_depth': max_depth,\n",
    "               \n",
    "               'min_samples_split': min_samples_split,\n",
    "               \n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               \n",
    "               'bootstrap': bootstrap}\n",
    "print(random_grid)\n",
    "\n",
    "{'bootstrap': [True, False],\n",
    "\n",
    " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    " \n",
    " 'max_features': ['auto', 'sqrt'],\n",
    " \n",
    " 'min_samples_leaf': [1, 2, 4],\n",
    " \n",
    " 'min_samples_split': [2, 5, 10],\n",
    " \n",
    " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #  Different hyperparameters for our LogisticRegression Model\n",
    "# np.random.seed(42)\n",
    "# model = RandomForestClassifier()\n",
    "# param_grid = {\n",
    "#     'n_estimators': [100, 200, 300,400,500],\n",
    "#     'max_depth': [10, 20, 30,40,50]\n",
    "# }\n",
    "# # here taking param_grid value anything as later on we will find it best param\n",
    "\n",
    "# # Setup grid hyperparameter search for LogisticRegression\n",
    "# gs_rf =GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "\n",
    "# # # Fit the model\n",
    "# gs_rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs_rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [50], &#x27;n_estimators&#x27;: [400]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [50], &#x27;n_estimators&#x27;: [400]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [50], 'n_estimators': [400]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Now lets train on new best param\n",
    "np.random.seed(42)\n",
    "model = RandomForestClassifier()\n",
    "param_grid = {\n",
    "    'n_estimators': [400],\n",
    "    'max_depth': [50]\n",
    "}\n",
    "# here taking param_grid value anything as later on we will find it best param\n",
    "\n",
    "# Setup grid hyperparameter search for LogisticRegression\n",
    "gs_rf = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "\n",
    "\n",
    "# # Fit the model\n",
    "gs_rf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9738751814223512"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_rf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl', 'wb') as f:\n",
    "    pickle.dump(gs_rf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds=gs_rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       691\n",
      "           1       0.96      0.99      0.97       687\n",
      "\n",
      "    accuracy                           0.97      1378\n",
      "   macro avg       0.97      0.97      0.97      1378\n",
      "weighted avg       0.97      0.97      0.97      1378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pkl', 'rb') as f:\n",
    "    loaded_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9738751814223512"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
