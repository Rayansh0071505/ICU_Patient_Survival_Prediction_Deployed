{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<h1> Mortality Predictions in ICU using ANN </h1>** \n",
    "\n",
    "Patients in the intensive care unit (ICU) face severe illness or injury and have a heightened risk of mortality. ICU mortality rates vary significantly based on the specific underlying condition, ranging from 1 in 20 for those admitted after planned surgeries to 1 in 4 for individuals with respiratory ailments. Assessing the likelihood of death involves evaluating the severity of a patient's illness through key physiological, clinical, and demographic factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle table-like data and matrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import neighbors\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix,classification_report, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "%matplotlib inline\n",
    "sb.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Age</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>DiasABP</th>\n",
       "      <th>...</th>\n",
       "      <th>RespRate</th>\n",
       "      <th>SaO2</th>\n",
       "      <th>SysABP</th>\n",
       "      <th>Temp</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>Urine</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Weight</th>\n",
       "      <th>pH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.00</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>54</td>\n",
       "      <td>2.973333</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>58.795833</td>\n",
       "      <td>...</td>\n",
       "      <td>17.428571</td>\n",
       "      <td>97.250000</td>\n",
       "      <td>116.891892</td>\n",
       "      <td>37.357143</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.140</td>\n",
       "      <td>171.052632</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>80.060976</td>\n",
       "      <td>7.387273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.00</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>76</td>\n",
       "      <td>2.973333</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>58.897059</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>96.833333</td>\n",
       "      <td>113.411765</td>\n",
       "      <td>36.939130</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.140</td>\n",
       "      <td>151.560976</td>\n",
       "      <td>11.266667</td>\n",
       "      <td>80.670588</td>\n",
       "      <td>7.395000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.0</td>\n",
       "      <td>83.00</td>\n",
       "      <td>199.500000</td>\n",
       "      <td>44</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>67.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>125.687500</td>\n",
       "      <td>37.800000</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.140</td>\n",
       "      <td>124.951219</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>56.700000</td>\n",
       "      <td>7.495000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105.0</td>\n",
       "      <td>12.00</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>68</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>17.666667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>58.795833</td>\n",
       "      <td>...</td>\n",
       "      <td>15.457627</td>\n",
       "      <td>97.250000</td>\n",
       "      <td>116.891892</td>\n",
       "      <td>36.223077</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.140</td>\n",
       "      <td>545.833333</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>84.600000</td>\n",
       "      <td>7.387273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.00</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>88</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>58.795833</td>\n",
       "      <td>...</td>\n",
       "      <td>19.166667</td>\n",
       "      <td>97.250000</td>\n",
       "      <td>116.891892</td>\n",
       "      <td>36.880000</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.140</td>\n",
       "      <td>62.131579</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>80.060976</td>\n",
       "      <td>7.387273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>82.0</td>\n",
       "      <td>32.25</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>70</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>145.0</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>68.865385</td>\n",
       "      <td>...</td>\n",
       "      <td>19.290323</td>\n",
       "      <td>97.230769</td>\n",
       "      <td>117.230769</td>\n",
       "      <td>37.004762</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.125</td>\n",
       "      <td>50.769231</td>\n",
       "      <td>14.500000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>7.381429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>82.0</td>\n",
       "      <td>32.25</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>25</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>58.754774</td>\n",
       "      <td>...</td>\n",
       "      <td>17.636364</td>\n",
       "      <td>97.230769</td>\n",
       "      <td>117.820733</td>\n",
       "      <td>36.580000</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.125</td>\n",
       "      <td>584.375000</td>\n",
       "      <td>4.733333</td>\n",
       "      <td>166.400000</td>\n",
       "      <td>7.385000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>51.0</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>44</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>74.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>19.290323</td>\n",
       "      <td>97.230769</td>\n",
       "      <td>125.666667</td>\n",
       "      <td>37.792308</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.125</td>\n",
       "      <td>116.472222</td>\n",
       "      <td>11.066667</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>7.396667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>169.0</td>\n",
       "      <td>1971.00</td>\n",
       "      <td>1685.333333</td>\n",
       "      <td>37</td>\n",
       "      <td>3.100000</td>\n",
       "      <td>89.250000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>145.0</td>\n",
       "      <td>9.650000</td>\n",
       "      <td>92.923077</td>\n",
       "      <td>...</td>\n",
       "      <td>19.290323</td>\n",
       "      <td>97.230769</td>\n",
       "      <td>166.615385</td>\n",
       "      <td>38.418182</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.125</td>\n",
       "      <td>11.230769</td>\n",
       "      <td>13.025000</td>\n",
       "      <td>87.400000</td>\n",
       "      <td>7.416000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>44.0</td>\n",
       "      <td>18.50</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>78</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>20.166667</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>145.0</td>\n",
       "      <td>1.116667</td>\n",
       "      <td>57.836957</td>\n",
       "      <td>...</td>\n",
       "      <td>19.290323</td>\n",
       "      <td>97.466667</td>\n",
       "      <td>111.532609</td>\n",
       "      <td>36.381395</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.125</td>\n",
       "      <td>57.750000</td>\n",
       "      <td>9.228571</td>\n",
       "      <td>87.838889</td>\n",
       "      <td>7.305600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3999 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ALP      ALT          AST  Age   Albumin        BUN  Bilirubin  \\\n",
       "0      77.0    31.00    46.000000   54  2.973333  10.500000   0.700000   \n",
       "1      77.0    31.00    46.000000   76  2.973333  18.333333   0.700000   \n",
       "2     116.0    83.00   199.500000   44  2.500000   4.666667   2.900000   \n",
       "3     105.0    12.00    15.000000   68  4.400000  17.666667   0.200000   \n",
       "4      77.0    31.00    46.000000   88  3.300000  35.000000   0.700000   \n",
       "...     ...      ...          ...  ...       ...        ...        ...   \n",
       "3994   82.0    32.25    49.000000   70  3.000000  16.000000   0.700000   \n",
       "3995   82.0    32.25    49.000000   25  3.000000   4.400000   0.700000   \n",
       "3996   51.0    20.00    20.000000   44  3.000000   7.750000   0.500000   \n",
       "3997  169.0  1971.00  1685.333333   37  3.100000  89.250000   0.733333   \n",
       "3998   44.0    18.50   126.000000   78  2.200000  20.166667   0.600000   \n",
       "\n",
       "      Cholesterol  Creatinine    DiasABP  ...   RespRate       SaO2  \\\n",
       "0           154.0    0.750000  58.795833  ...  17.428571  97.250000   \n",
       "1           154.0    1.100000  58.897059  ...  19.000000  96.833333   \n",
       "2           154.0    0.333333  67.125000  ...  19.000000  95.000000   \n",
       "3           154.0    0.766667  58.795833  ...  15.457627  97.250000   \n",
       "4           154.0    1.000000  58.795833  ...  19.166667  97.250000   \n",
       "...           ...         ...        ...  ...        ...        ...   \n",
       "3994        145.0    0.900000  68.865385  ...  19.290323  97.230769   \n",
       "3995        117.0    0.840000  58.754774  ...  17.636364  97.230769   \n",
       "3996        145.0    1.125000  74.166667  ...  19.290323  97.230769   \n",
       "3997        145.0    9.650000  92.923077  ...  19.290323  97.230769   \n",
       "3998        145.0    1.116667  57.836957  ...  19.290323  97.466667   \n",
       "\n",
       "          SysABP       Temp  TroponinI  TroponinT       Urine        WBC  \\\n",
       "0     116.891892  37.357143        2.1      0.140  171.052632  10.300000   \n",
       "1     113.411765  36.939130        2.1      0.140  151.560976  11.266667   \n",
       "2     125.687500  37.800000        2.1      0.140  124.951219   4.700000   \n",
       "3     116.891892  36.223077        2.1      0.140  545.833333   9.400000   \n",
       "4     116.891892  36.880000        2.1      0.140   62.131579   4.300000   \n",
       "...          ...        ...        ...        ...         ...        ...   \n",
       "3994  117.230769  37.004762        2.2      0.125   50.769231  14.500000   \n",
       "3995  117.820733  36.580000        2.2      0.125  584.375000   4.733333   \n",
       "3996  125.666667  37.792308        2.2      0.125  116.472222  11.066667   \n",
       "3997  166.615385  38.418182        2.2      0.125   11.230769  13.025000   \n",
       "3998  111.532609  36.381395        2.2      0.125   57.750000   9.228571   \n",
       "\n",
       "          Weight        pH  \n",
       "0      80.060976  7.387273  \n",
       "1      80.670588  7.395000  \n",
       "2      56.700000  7.495000  \n",
       "3      84.600000  7.387273  \n",
       "4      80.060976  7.387273  \n",
       "...          ...       ...  \n",
       "3994   87.000000  7.381429  \n",
       "3995  166.400000  7.385000  \n",
       "3996  109.000000  7.396667  \n",
       "3997   87.400000  7.416000  \n",
       "3998   87.838889  7.305600  \n",
       "\n",
       "[3999 rows x 42 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv',encoding='utf-8')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>In-hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3999 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      In-hospital_death\n",
       "0                     0\n",
       "1                     0\n",
       "2                     0\n",
       "3                     0\n",
       "4                     0\n",
       "...                 ...\n",
       "3994                  0\n",
       "3995                  0\n",
       "3996                  0\n",
       "3997                  1\n",
       "3998                  0\n",
       "\n",
       "[3999 rows x 1 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv('labels.csv',encoding = 'utf-8')\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check for data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3999 entries, 0 to 3998\n",
      "Data columns (total 42 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   ALP          3999 non-null   float64\n",
      " 1   ALT          3999 non-null   float64\n",
      " 2   AST          3999 non-null   float64\n",
      " 3   Age          3999 non-null   int64  \n",
      " 4   Albumin      3999 non-null   float64\n",
      " 5   BUN          3999 non-null   float64\n",
      " 6   Bilirubin    3999 non-null   float64\n",
      " 7   Cholesterol  3999 non-null   float64\n",
      " 8   Creatinine   3999 non-null   float64\n",
      " 9   DiasABP      3999 non-null   float64\n",
      " 10  FiO2         3999 non-null   float64\n",
      " 11  GCS          3999 non-null   float64\n",
      " 12  Gender       3999 non-null   int64  \n",
      " 13  Glucose      3999 non-null   float64\n",
      " 14  HCO3         3999 non-null   float64\n",
      " 15  HCT          3999 non-null   float64\n",
      " 16  HR           3999 non-null   float64\n",
      " 17  Height       3999 non-null   float64\n",
      " 18  ICUType      3999 non-null   int64  \n",
      " 19  K            3999 non-null   float64\n",
      " 20  Lactate      3999 non-null   float64\n",
      " 21  MAP          3999 non-null   float64\n",
      " 22  MechVent     3999 non-null   int64  \n",
      " 23  Mg           3999 non-null   float64\n",
      " 24  NIDiasABP    3999 non-null   float64\n",
      " 25  NIMAP        3999 non-null   float64\n",
      " 26  NISysABP     3999 non-null   float64\n",
      " 27  Na           3999 non-null   float64\n",
      " 28  PaCO2        3999 non-null   float64\n",
      " 29  PaO2         3999 non-null   float64\n",
      " 30  Platelets    3999 non-null   float64\n",
      " 31  RecordID     3999 non-null   float64\n",
      " 32  RespRate     3999 non-null   float64\n",
      " 33  SaO2         3999 non-null   float64\n",
      " 34  SysABP       3999 non-null   float64\n",
      " 35  Temp         3999 non-null   float64\n",
      " 36  TroponinI    3999 non-null   float64\n",
      " 37  TroponinT    3999 non-null   float64\n",
      " 38  Urine        3999 non-null   float64\n",
      " 39  WBC          3999 non-null   float64\n",
      " 40  Weight       3999 non-null   float64\n",
      " 41  pH           3999 non-null   float64\n",
      "dtypes: float64(38), int64(4)\n",
      "memory usage: 1.3 MB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3999 entries, 0 to 3998\n",
      "Data columns (total 1 columns):\n",
      " #   Column             Non-Null Count  Dtype\n",
      "---  ------             --------------  -----\n",
      " 0   In-hospital_death  3999 non-null   int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 31.4 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.info(),labels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ALP            0\n",
       " ALT            0\n",
       " AST            0\n",
       " Age            0\n",
       " Albumin        0\n",
       " BUN            0\n",
       " Bilirubin      0\n",
       " Cholesterol    0\n",
       " Creatinine     0\n",
       " DiasABP        0\n",
       " FiO2           0\n",
       " GCS            0\n",
       " Gender         0\n",
       " Glucose        0\n",
       " HCO3           0\n",
       " HCT            0\n",
       " HR             0\n",
       " Height         0\n",
       " ICUType        0\n",
       " K              0\n",
       " Lactate        0\n",
       " MAP            0\n",
       " MechVent       0\n",
       " Mg             0\n",
       " NIDiasABP      0\n",
       " NIMAP          0\n",
       " NISysABP       0\n",
       " Na             0\n",
       " PaCO2          0\n",
       " PaO2           0\n",
       " Platelets      0\n",
       " RecordID       0\n",
       " RespRate       0\n",
       " SaO2           0\n",
       " SysABP         0\n",
       " Temp           0\n",
       " TroponinI      0\n",
       " TroponinT      0\n",
       " Urine          0\n",
       " WBC            0\n",
       " Weight         0\n",
       " pH             0\n",
       " dtype: int64,\n",
       " In-hospital_death    0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum(),labels.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data is cleaned no need to clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALP',\n",
       " 'ALT',\n",
       " 'AST',\n",
       " 'Age',\n",
       " 'Albumin',\n",
       " 'BUN',\n",
       " 'Bilirubin',\n",
       " 'Cholesterol',\n",
       " 'Creatinine',\n",
       " 'DiasABP',\n",
       " 'FiO2',\n",
       " 'GCS',\n",
       " 'Gender',\n",
       " 'Glucose',\n",
       " 'HCO3',\n",
       " 'HCT',\n",
       " 'HR',\n",
       " 'Height',\n",
       " 'ICUType',\n",
       " 'K',\n",
       " 'Lactate',\n",
       " 'MAP',\n",
       " 'MechVent',\n",
       " 'Mg',\n",
       " 'NIDiasABP',\n",
       " 'NIMAP',\n",
       " 'NISysABP',\n",
       " 'Na',\n",
       " 'PaCO2',\n",
       " 'PaO2',\n",
       " 'Platelets',\n",
       " 'RecordID',\n",
       " 'RespRate',\n",
       " 'SaO2',\n",
       " 'SysABP',\n",
       " 'Temp',\n",
       " 'TroponinI',\n",
       " 'TroponinT',\n",
       " 'Urine',\n",
       " 'WBC',\n",
       " 'Weight',\n",
       " 'pH']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3999, 42), (3999, 1))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape,labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Age</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>DiasABP</th>\n",
       "      <th>...</th>\n",
       "      <th>RespRate</th>\n",
       "      <th>SaO2</th>\n",
       "      <th>SysABP</th>\n",
       "      <th>Temp</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>Urine</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Weight</th>\n",
       "      <th>pH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "      <td>3999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>89.259978</td>\n",
       "      <td>91.709903</td>\n",
       "      <td>130.219258</td>\n",
       "      <td>64.247562</td>\n",
       "      <td>2.975942</td>\n",
       "      <td>25.449665</td>\n",
       "      <td>1.216527</td>\n",
       "      <td>152.403601</td>\n",
       "      <td>1.363130</td>\n",
       "      <td>59.262693</td>\n",
       "      <td>...</td>\n",
       "      <td>19.223967</td>\n",
       "      <td>96.940907</td>\n",
       "      <td>118.145550</td>\n",
       "      <td>36.956291</td>\n",
       "      <td>2.368702</td>\n",
       "      <td>0.337362</td>\n",
       "      <td>133.363074</td>\n",
       "      <td>12.521058</td>\n",
       "      <td>82.799384</td>\n",
       "      <td>7.488870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>70.397850</td>\n",
       "      <td>427.290858</td>\n",
       "      <td>590.482153</td>\n",
       "      <td>17.563142</td>\n",
       "      <td>0.404440</td>\n",
       "      <td>20.586576</td>\n",
       "      <td>2.961385</td>\n",
       "      <td>13.891279</td>\n",
       "      <td>1.406947</td>\n",
       "      <td>9.080069</td>\n",
       "      <td>...</td>\n",
       "      <td>2.074830</td>\n",
       "      <td>2.296143</td>\n",
       "      <td>16.540816</td>\n",
       "      <td>0.727382</td>\n",
       "      <td>2.418656</td>\n",
       "      <td>1.276145</td>\n",
       "      <td>117.304284</td>\n",
       "      <td>6.466063</td>\n",
       "      <td>23.117431</td>\n",
       "      <td>2.986373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.543478</td>\n",
       "      <td>38.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.644615</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>6.311667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>52.500000</td>\n",
       "      <td>2.973333</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>55.843712</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>97.230769</td>\n",
       "      <td>111.099359</td>\n",
       "      <td>36.614286</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>74.044118</td>\n",
       "      <td>8.900000</td>\n",
       "      <td>68.201064</td>\n",
       "      <td>7.364142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>67.000000</td>\n",
       "      <td>2.973333</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>58.795833</td>\n",
       "      <td>...</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>97.250000</td>\n",
       "      <td>116.891892</td>\n",
       "      <td>36.968750</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>111.032258</td>\n",
       "      <td>11.466667</td>\n",
       "      <td>80.060976</td>\n",
       "      <td>7.387273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>32.250000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>154.000000</td>\n",
       "      <td>1.366667</td>\n",
       "      <td>62.210006</td>\n",
       "      <td>...</td>\n",
       "      <td>19.290323</td>\n",
       "      <td>97.250000</td>\n",
       "      <td>123.504098</td>\n",
       "      <td>37.364401</td>\n",
       "      <td>2.100000</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>160.419207</td>\n",
       "      <td>14.950000</td>\n",
       "      <td>93.040476</td>\n",
       "      <td>7.407500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1472.333333</td>\n",
       "      <td>9143.428571</td>\n",
       "      <td>15680.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>170.833333</td>\n",
       "      <td>46.366667</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>16.457143</td>\n",
       "      <td>106.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>39.655172</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>181.725000</td>\n",
       "      <td>39.748980</td>\n",
       "      <td>49.200000</td>\n",
       "      <td>24.040000</td>\n",
       "      <td>3082.380952</td>\n",
       "      <td>137.233333</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>128.532500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ALP          ALT           AST          Age      Albumin  \\\n",
       "count  3999.000000  3999.000000   3999.000000  3999.000000  3999.000000   \n",
       "mean     89.259978    91.709903    130.219258    64.247562     2.975942   \n",
       "std      70.397850   427.290858    590.482153    17.563142     0.404440   \n",
       "min      12.000000     3.000000      6.000000    15.000000     1.100000   \n",
       "25%      77.000000    31.000000     46.000000    52.500000     2.973333   \n",
       "50%      77.000000    31.000000     46.000000    67.000000     2.973333   \n",
       "75%      82.000000    32.250000     49.000000    78.000000     3.000000   \n",
       "max    1472.333333  9143.428571  15680.000000    90.000000     5.300000   \n",
       "\n",
       "               BUN    Bilirubin  Cholesterol   Creatinine      DiasABP  ...  \\\n",
       "count  3999.000000  3999.000000  3999.000000  3999.000000  3999.000000  ...   \n",
       "mean     25.449665     1.216527   152.403601     1.363130    59.262693  ...   \n",
       "std      20.586576     2.961385    13.891279     1.406947     9.080069  ...   \n",
       "min       2.250000     0.100000     0.000000     0.200000     0.000000  ...   \n",
       "25%      13.000000     0.700000   154.000000     0.700000    55.843712  ...   \n",
       "50%      19.000000     0.700000   154.000000     0.933333    58.795833  ...   \n",
       "75%      30.000000     0.700000   154.000000     1.366667    62.210006  ...   \n",
       "max     170.833333    46.366667   330.000000    16.457143   106.666667  ...   \n",
       "\n",
       "          RespRate         SaO2       SysABP         Temp    TroponinI  \\\n",
       "count  3999.000000  3999.000000  3999.000000  3999.000000  3999.000000   \n",
       "mean     19.223967    96.940907   118.145550    36.956291     2.368702   \n",
       "std       2.074830     2.296143    16.540816     0.727382     2.418656   \n",
       "min      10.543478    38.800000     0.000000    21.644615     0.300000   \n",
       "25%      19.000000    97.230769   111.099359    36.614286     2.100000   \n",
       "50%      19.000000    97.250000   116.891892    36.968750     2.100000   \n",
       "75%      19.290323    97.250000   123.504098    37.364401     2.100000   \n",
       "max      39.655172   100.000000   181.725000    39.748980    49.200000   \n",
       "\n",
       "         TroponinT        Urine          WBC       Weight           pH  \n",
       "count  3999.000000  3999.000000  3999.000000  3999.000000  3999.000000  \n",
       "mean      0.337362   133.363074    12.521058    82.799384     7.488870  \n",
       "std       1.276145   117.304284     6.466063    23.117431     2.986373  \n",
       "min       0.010000     0.000000     0.100000     3.500000     6.311667  \n",
       "25%       0.125000    74.044118     8.900000    68.201064     7.364142  \n",
       "50%       0.140000   111.032258    11.466667    80.060976     7.387273  \n",
       "75%       0.140000   160.419207    14.950000    93.040476     7.407500  \n",
       "max      24.040000  3082.380952   137.233333   300.000000   128.532500  \n",
       "\n",
       "[8 rows x 42 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>In-hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.138535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.345503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       In-hospital_death\n",
       "count        3999.000000\n",
       "mean            0.138535\n",
       "std             0.345503\n",
       "min             0.000000\n",
       "25%             0.000000\n",
       "50%             0.000000\n",
       "75%             0.000000\n",
       "max             1.000000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Variable - Outcome\n",
    "0 - Alive\n",
    "\n",
    "1 - Death"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3445\n",
       "1     554\n",
       "Name: In-hospital_death, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[\"In-hospital_death\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets do One Hot Encoding\n",
    "\n",
    "#### Benifits are - \n",
    "One-hot encoding is like giving each category its special code so a computer can understand and work with it better. Imagine you have three types of fruits: apples, bananas, and oranges. Instead of saying \"apple,\" \"banana,\" or \"orange,\" we assign a special code for each: 001 for apple, 010 for banana, and 100 for orange.\n",
    "\n",
    "Why is this helpful?\n",
    "\n",
    "1. **Simplicity for Computers**: Computers find it easier to work with numbers. With one-hot encoding, we convert categories into simple numbers (0s and 1s).\n",
    "\n",
    "2. **Avoiding Confusion**: We want to make sure the computer doesn't get confused into thinking apples (0, 0, 1) are like bananas (0, 1, 0) or oranges (1, 0, 0).\n",
    "\n",
    "3. **Equal Importance**: Each category gets its own unique code, showing that they are equally important and unrelated in terms of the task at hand.\n",
    "\n",
    "4. **Compatible with Algorithms**: Many machine learning algorithms need numerical data to train and make predictions. One-hot encoding allows us to use these algorithms with categorical data.\n",
    "\n",
    "In a nutshell, one-hot encoding helps the computer understand categories in a clear and organized way, making it easier for us to build models that learn and make accurate predictions based on these categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding\n",
    "one_hot_encoded_label = []\n",
    "for i in labels[\"In-hospital_death\"]:\n",
    "    if i == 0:\n",
    "        one_hot_encoded_label.append([1,0])\n",
    "    else:\n",
    "        one_hot_encoded_label.append([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1\n",
       "0  1  0\n",
       "1  1  0\n",
       "2  1  0\n",
       "3  1  0\n",
       "4  1  0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### To understand properly lets see the data\n",
    "one_hot_encoded_data = pd.DataFrame(one_hot_encoded_label)\n",
    "one_hot_encoded_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Age</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>DiasABP</th>\n",
       "      <th>...</th>\n",
       "      <th>SaO2</th>\n",
       "      <th>SysABP</th>\n",
       "      <th>Temp</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>Urine</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Weight</th>\n",
       "      <th>pH</th>\n",
       "      <th>In-hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>54</td>\n",
       "      <td>2.973333</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>58.795833</td>\n",
       "      <td>...</td>\n",
       "      <td>97.250000</td>\n",
       "      <td>116.891892</td>\n",
       "      <td>37.357143</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>171.052632</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>80.060976</td>\n",
       "      <td>7.387273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>76</td>\n",
       "      <td>2.973333</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>58.897059</td>\n",
       "      <td>...</td>\n",
       "      <td>96.833333</td>\n",
       "      <td>113.411765</td>\n",
       "      <td>36.939130</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>151.560976</td>\n",
       "      <td>11.266667</td>\n",
       "      <td>80.670588</td>\n",
       "      <td>7.395000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>199.5</td>\n",
       "      <td>44</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.9</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>67.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>125.687500</td>\n",
       "      <td>37.800000</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>124.951219</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>56.700000</td>\n",
       "      <td>7.495000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>68</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>17.666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>154.0</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>58.795833</td>\n",
       "      <td>...</td>\n",
       "      <td>97.250000</td>\n",
       "      <td>116.891892</td>\n",
       "      <td>36.223077</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>545.833333</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>84.600000</td>\n",
       "      <td>7.387273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>88</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>154.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>58.795833</td>\n",
       "      <td>...</td>\n",
       "      <td>97.250000</td>\n",
       "      <td>116.891892</td>\n",
       "      <td>36.880000</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>62.131579</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>80.060976</td>\n",
       "      <td>7.387273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ALP   ALT    AST  Age   Albumin        BUN  Bilirubin  Cholesterol  \\\n",
       "0   77.0  31.0   46.0   54  2.973333  10.500000        0.7        154.0   \n",
       "1   77.0  31.0   46.0   76  2.973333  18.333333        0.7        154.0   \n",
       "2  116.0  83.0  199.5   44  2.500000   4.666667        2.9        154.0   \n",
       "3  105.0  12.0   15.0   68  4.400000  17.666667        0.2        154.0   \n",
       "4   77.0  31.0   46.0   88  3.300000  35.000000        0.7        154.0   \n",
       "\n",
       "   Creatinine    DiasABP  ...       SaO2      SysABP       Temp  TroponinI  \\\n",
       "0    0.750000  58.795833  ...  97.250000  116.891892  37.357143        2.1   \n",
       "1    1.100000  58.897059  ...  96.833333  113.411765  36.939130        2.1   \n",
       "2    0.333333  67.125000  ...  95.000000  125.687500  37.800000        2.1   \n",
       "3    0.766667  58.795833  ...  97.250000  116.891892  36.223077        2.1   \n",
       "4    1.000000  58.795833  ...  97.250000  116.891892  36.880000        2.1   \n",
       "\n",
       "   TroponinT       Urine        WBC     Weight        pH  In-hospital_death  \n",
       "0       0.14  171.052632  10.300000  80.060976  7.387273                  0  \n",
       "1       0.14  151.560976  11.266667  80.670588  7.395000                  0  \n",
       "2       0.14  124.951219   4.700000  56.700000  7.495000                  0  \n",
       "3       0.14  545.833333   9.400000  84.600000  7.387273                  0  \n",
       "4       0.14   62.131579   4.300000  80.060976  7.387273                  0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets visualise it\n",
    "merged_data=pd.concat([data,labels],axis=1)\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Age</th>\n",
       "      <th>Albumin</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>DiasABP</th>\n",
       "      <th>...</th>\n",
       "      <th>SaO2</th>\n",
       "      <th>SysABP</th>\n",
       "      <th>Temp</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>Urine</th>\n",
       "      <th>WBC</th>\n",
       "      <th>Weight</th>\n",
       "      <th>pH</th>\n",
       "      <th>In-hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALP</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.114850</td>\n",
       "      <td>0.155750</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>-0.137771</td>\n",
       "      <td>0.155416</td>\n",
       "      <td>0.240297</td>\n",
       "      <td>-0.006795</td>\n",
       "      <td>0.131899</td>\n",
       "      <td>-0.035320</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024257</td>\n",
       "      <td>-0.052407</td>\n",
       "      <td>-0.051107</td>\n",
       "      <td>-0.011932</td>\n",
       "      <td>-0.019689</td>\n",
       "      <td>-0.040027</td>\n",
       "      <td>0.085952</td>\n",
       "      <td>-0.021914</td>\n",
       "      <td>-0.005073</td>\n",
       "      <td>0.115577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALT</th>\n",
       "      <td>0.114850</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.858741</td>\n",
       "      <td>-0.112012</td>\n",
       "      <td>-0.009850</td>\n",
       "      <td>0.038541</td>\n",
       "      <td>0.109332</td>\n",
       "      <td>-0.024351</td>\n",
       "      <td>0.077210</td>\n",
       "      <td>0.024430</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067018</td>\n",
       "      <td>-0.050335</td>\n",
       "      <td>-0.017507</td>\n",
       "      <td>-0.011350</td>\n",
       "      <td>0.037490</td>\n",
       "      <td>-0.048773</td>\n",
       "      <td>0.013325</td>\n",
       "      <td>-0.001541</td>\n",
       "      <td>-0.004561</td>\n",
       "      <td>0.070992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AST</th>\n",
       "      <td>0.155750</td>\n",
       "      <td>0.858741</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.088649</td>\n",
       "      <td>-0.037277</td>\n",
       "      <td>0.051244</td>\n",
       "      <td>0.127767</td>\n",
       "      <td>-0.020751</td>\n",
       "      <td>0.092024</td>\n",
       "      <td>0.030425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095091</td>\n",
       "      <td>-0.053931</td>\n",
       "      <td>-0.014374</td>\n",
       "      <td>-0.012664</td>\n",
       "      <td>0.081825</td>\n",
       "      <td>-0.064821</td>\n",
       "      <td>0.032749</td>\n",
       "      <td>0.008551</td>\n",
       "      <td>-0.001068</td>\n",
       "      <td>0.108484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.000879</td>\n",
       "      <td>-0.112012</td>\n",
       "      <td>-0.088649</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.036231</td>\n",
       "      <td>0.228768</td>\n",
       "      <td>-0.063837</td>\n",
       "      <td>-0.010103</td>\n",
       "      <td>0.033369</td>\n",
       "      <td>-0.263634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021496</td>\n",
       "      <td>0.009608</td>\n",
       "      <td>-0.146972</td>\n",
       "      <td>0.043898</td>\n",
       "      <td>0.051547</td>\n",
       "      <td>-0.255105</td>\n",
       "      <td>0.034414</td>\n",
       "      <td>-0.177945</td>\n",
       "      <td>0.025433</td>\n",
       "      <td>0.130701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Albumin</th>\n",
       "      <td>-0.137771</td>\n",
       "      <td>-0.009850</td>\n",
       "      <td>-0.037277</td>\n",
       "      <td>-0.036231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.100987</td>\n",
       "      <td>-0.086068</td>\n",
       "      <td>0.058119</td>\n",
       "      <td>-0.030867</td>\n",
       "      <td>0.077583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035633</td>\n",
       "      <td>0.103017</td>\n",
       "      <td>0.006044</td>\n",
       "      <td>0.009577</td>\n",
       "      <td>0.039915</td>\n",
       "      <td>0.102044</td>\n",
       "      <td>-0.099285</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.007397</td>\n",
       "      <td>-0.126925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUN</th>\n",
       "      <td>0.155416</td>\n",
       "      <td>0.038541</td>\n",
       "      <td>0.051244</td>\n",
       "      <td>0.228768</td>\n",
       "      <td>-0.100987</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.185473</td>\n",
       "      <td>-0.014453</td>\n",
       "      <td>0.683278</td>\n",
       "      <td>-0.119703</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037919</td>\n",
       "      <td>-0.042018</td>\n",
       "      <td>-0.182530</td>\n",
       "      <td>0.072952</td>\n",
       "      <td>0.042128</td>\n",
       "      <td>-0.195167</td>\n",
       "      <td>0.101356</td>\n",
       "      <td>0.079346</td>\n",
       "      <td>-0.007620</td>\n",
       "      <td>0.223369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bilirubin</th>\n",
       "      <td>0.240297</td>\n",
       "      <td>0.109332</td>\n",
       "      <td>0.127767</td>\n",
       "      <td>-0.063837</td>\n",
       "      <td>-0.086068</td>\n",
       "      <td>0.185473</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.017119</td>\n",
       "      <td>0.140630</td>\n",
       "      <td>-0.031563</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003182</td>\n",
       "      <td>-0.053594</td>\n",
       "      <td>-0.091075</td>\n",
       "      <td>-0.007221</td>\n",
       "      <td>-0.016851</td>\n",
       "      <td>-0.076323</td>\n",
       "      <td>0.018515</td>\n",
       "      <td>0.033972</td>\n",
       "      <td>-0.006371</td>\n",
       "      <td>0.174017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cholesterol</th>\n",
       "      <td>-0.006795</td>\n",
       "      <td>-0.024351</td>\n",
       "      <td>-0.020751</td>\n",
       "      <td>-0.010103</td>\n",
       "      <td>0.058119</td>\n",
       "      <td>-0.014453</td>\n",
       "      <td>-0.017119</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.023809</td>\n",
       "      <td>0.072380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008578</td>\n",
       "      <td>0.011681</td>\n",
       "      <td>0.014865</td>\n",
       "      <td>-0.021201</td>\n",
       "      <td>0.036640</td>\n",
       "      <td>0.013926</td>\n",
       "      <td>-0.010553</td>\n",
       "      <td>-0.012247</td>\n",
       "      <td>-0.004304</td>\n",
       "      <td>-0.008578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Creatinine</th>\n",
       "      <td>0.131899</td>\n",
       "      <td>0.077210</td>\n",
       "      <td>0.092024</td>\n",
       "      <td>0.033369</td>\n",
       "      <td>-0.030867</td>\n",
       "      <td>0.683278</td>\n",
       "      <td>0.140630</td>\n",
       "      <td>-0.023809</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.072456</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019475</td>\n",
       "      <td>-0.030945</td>\n",
       "      <td>-0.108552</td>\n",
       "      <td>0.034726</td>\n",
       "      <td>0.047885</td>\n",
       "      <td>-0.162525</td>\n",
       "      <td>0.032108</td>\n",
       "      <td>0.091286</td>\n",
       "      <td>0.006364</td>\n",
       "      <td>0.117615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiasABP</th>\n",
       "      <td>-0.035320</td>\n",
       "      <td>0.024430</td>\n",
       "      <td>0.030425</td>\n",
       "      <td>-0.263634</td>\n",
       "      <td>0.077583</td>\n",
       "      <td>-0.119703</td>\n",
       "      <td>-0.031563</td>\n",
       "      <td>0.072380</td>\n",
       "      <td>-0.072456</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003486</td>\n",
       "      <td>0.594665</td>\n",
       "      <td>0.047105</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>0.119911</td>\n",
       "      <td>-0.019035</td>\n",
       "      <td>0.045176</td>\n",
       "      <td>-0.011028</td>\n",
       "      <td>-0.050506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FiO2</th>\n",
       "      <td>-0.003474</td>\n",
       "      <td>-0.003840</td>\n",
       "      <td>-0.003814</td>\n",
       "      <td>-0.011746</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>-0.009474</td>\n",
       "      <td>-0.004779</td>\n",
       "      <td>-0.299331</td>\n",
       "      <td>-0.008805</td>\n",
       "      <td>-0.169800</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003533</td>\n",
       "      <td>-0.001053</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>-0.002287</td>\n",
       "      <td>-0.004453</td>\n",
       "      <td>-0.004723</td>\n",
       "      <td>-0.004137</td>\n",
       "      <td>-0.003293</td>\n",
       "      <td>-0.000945</td>\n",
       "      <td>-0.010986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GCS</th>\n",
       "      <td>0.020718</td>\n",
       "      <td>-0.073180</td>\n",
       "      <td>-0.123846</td>\n",
       "      <td>0.027736</td>\n",
       "      <td>0.144026</td>\n",
       "      <td>-0.031887</td>\n",
       "      <td>-0.042079</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>-0.021087</td>\n",
       "      <td>-0.052003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031215</td>\n",
       "      <td>-0.004390</td>\n",
       "      <td>-0.182994</td>\n",
       "      <td>-0.015576</td>\n",
       "      <td>-0.024584</td>\n",
       "      <td>0.160777</td>\n",
       "      <td>-0.107853</td>\n",
       "      <td>-0.052356</td>\n",
       "      <td>0.013951</td>\n",
       "      <td>-0.254104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>-0.002758</td>\n",
       "      <td>-0.002251</td>\n",
       "      <td>-0.002259</td>\n",
       "      <td>-0.020055</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>-0.004939</td>\n",
       "      <td>-0.002749</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>-0.004057</td>\n",
       "      <td>-0.059151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002127</td>\n",
       "      <td>-0.001196</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>-0.001756</td>\n",
       "      <td>-0.002442</td>\n",
       "      <td>-0.002989</td>\n",
       "      <td>-0.002588</td>\n",
       "      <td>-0.001816</td>\n",
       "      <td>-0.000540</td>\n",
       "      <td>-0.006346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glucose</th>\n",
       "      <td>0.014560</td>\n",
       "      <td>0.049459</td>\n",
       "      <td>0.076040</td>\n",
       "      <td>0.057239</td>\n",
       "      <td>0.030054</td>\n",
       "      <td>0.126179</td>\n",
       "      <td>-0.029639</td>\n",
       "      <td>0.039647</td>\n",
       "      <td>0.037075</td>\n",
       "      <td>0.009471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.035862</td>\n",
       "      <td>-0.033763</td>\n",
       "      <td>0.031719</td>\n",
       "      <td>0.043126</td>\n",
       "      <td>-0.020630</td>\n",
       "      <td>0.050115</td>\n",
       "      <td>0.066428</td>\n",
       "      <td>0.001707</td>\n",
       "      <td>0.105764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HCO3</th>\n",
       "      <td>-0.095050</td>\n",
       "      <td>-0.088142</td>\n",
       "      <td>-0.117626</td>\n",
       "      <td>0.008126</td>\n",
       "      <td>0.182131</td>\n",
       "      <td>-0.236730</td>\n",
       "      <td>-0.132563</td>\n",
       "      <td>0.020805</td>\n",
       "      <td>-0.237834</td>\n",
       "      <td>0.029013</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.048361</td>\n",
       "      <td>0.097960</td>\n",
       "      <td>0.064890</td>\n",
       "      <td>-0.021523</td>\n",
       "      <td>-0.045145</td>\n",
       "      <td>0.101372</td>\n",
       "      <td>-0.123303</td>\n",
       "      <td>0.075300</td>\n",
       "      <td>-0.016808</td>\n",
       "      <td>-0.129574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HCT</th>\n",
       "      <td>-0.010624</td>\n",
       "      <td>0.047127</td>\n",
       "      <td>0.022552</td>\n",
       "      <td>-0.065288</td>\n",
       "      <td>0.228917</td>\n",
       "      <td>-0.096426</td>\n",
       "      <td>-0.040429</td>\n",
       "      <td>0.074143</td>\n",
       "      <td>-0.057180</td>\n",
       "      <td>0.199300</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049210</td>\n",
       "      <td>0.071777</td>\n",
       "      <td>-0.032963</td>\n",
       "      <td>0.002804</td>\n",
       "      <td>0.078635</td>\n",
       "      <td>0.099207</td>\n",
       "      <td>0.044376</td>\n",
       "      <td>0.040221</td>\n",
       "      <td>0.001903</td>\n",
       "      <td>-0.009584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HR</th>\n",
       "      <td>0.026164</td>\n",
       "      <td>0.091215</td>\n",
       "      <td>0.104572</td>\n",
       "      <td>-0.246909</td>\n",
       "      <td>-0.137857</td>\n",
       "      <td>-0.060862</td>\n",
       "      <td>0.019632</td>\n",
       "      <td>-0.040332</td>\n",
       "      <td>-0.032015</td>\n",
       "      <td>0.136714</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042553</td>\n",
       "      <td>-0.152790</td>\n",
       "      <td>0.205528</td>\n",
       "      <td>-0.007784</td>\n",
       "      <td>-0.013808</td>\n",
       "      <td>-0.028292</td>\n",
       "      <td>0.114941</td>\n",
       "      <td>0.020675</td>\n",
       "      <td>0.014498</td>\n",
       "      <td>0.073561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Height</th>\n",
       "      <td>-0.014689</td>\n",
       "      <td>0.012009</td>\n",
       "      <td>0.016882</td>\n",
       "      <td>-0.088042</td>\n",
       "      <td>0.018550</td>\n",
       "      <td>0.023661</td>\n",
       "      <td>0.012634</td>\n",
       "      <td>0.006758</td>\n",
       "      <td>0.047051</td>\n",
       "      <td>0.046366</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018500</td>\n",
       "      <td>0.003668</td>\n",
       "      <td>0.020027</td>\n",
       "      <td>0.001599</td>\n",
       "      <td>0.006398</td>\n",
       "      <td>0.025509</td>\n",
       "      <td>-0.006818</td>\n",
       "      <td>0.124226</td>\n",
       "      <td>-0.011014</td>\n",
       "      <td>-0.012456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ICUType</th>\n",
       "      <td>-0.002739</td>\n",
       "      <td>-0.002238</td>\n",
       "      <td>-0.002260</td>\n",
       "      <td>0.021302</td>\n",
       "      <td>-0.000138</td>\n",
       "      <td>-0.004988</td>\n",
       "      <td>-0.002727</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>-0.004856</td>\n",
       "      <td>-0.064856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002142</td>\n",
       "      <td>-0.001107</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>-0.001787</td>\n",
       "      <td>-0.002547</td>\n",
       "      <td>-0.003018</td>\n",
       "      <td>-0.002582</td>\n",
       "      <td>-0.001878</td>\n",
       "      <td>-0.000546</td>\n",
       "      <td>-0.006314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K</th>\n",
       "      <td>0.018410</td>\n",
       "      <td>-0.004501</td>\n",
       "      <td>0.031697</td>\n",
       "      <td>0.081105</td>\n",
       "      <td>-0.049365</td>\n",
       "      <td>0.264277</td>\n",
       "      <td>-0.020082</td>\n",
       "      <td>0.012194</td>\n",
       "      <td>0.285873</td>\n",
       "      <td>-0.108060</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.038602</td>\n",
       "      <td>-0.104015</td>\n",
       "      <td>-0.068384</td>\n",
       "      <td>0.003915</td>\n",
       "      <td>0.013367</td>\n",
       "      <td>-0.109000</td>\n",
       "      <td>0.067543</td>\n",
       "      <td>0.145366</td>\n",
       "      <td>0.010682</td>\n",
       "      <td>0.018713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Lactate</th>\n",
       "      <td>0.047983</td>\n",
       "      <td>0.193083</td>\n",
       "      <td>0.282596</td>\n",
       "      <td>-0.018507</td>\n",
       "      <td>-0.066734</td>\n",
       "      <td>0.037174</td>\n",
       "      <td>0.103735</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>0.047987</td>\n",
       "      <td>-0.041495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052907</td>\n",
       "      <td>-0.066719</td>\n",
       "      <td>-0.033017</td>\n",
       "      <td>-0.007629</td>\n",
       "      <td>0.019889</td>\n",
       "      <td>-0.038360</td>\n",
       "      <td>0.046109</td>\n",
       "      <td>0.014322</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.124184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAP</th>\n",
       "      <td>-0.017456</td>\n",
       "      <td>0.021525</td>\n",
       "      <td>-0.000306</td>\n",
       "      <td>-0.114144</td>\n",
       "      <td>0.091947</td>\n",
       "      <td>-0.080205</td>\n",
       "      <td>-0.032284</td>\n",
       "      <td>0.027633</td>\n",
       "      <td>-0.054207</td>\n",
       "      <td>0.450196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026236</td>\n",
       "      <td>0.346110</td>\n",
       "      <td>0.034847</td>\n",
       "      <td>0.001332</td>\n",
       "      <td>-0.020526</td>\n",
       "      <td>0.079936</td>\n",
       "      <td>-0.039635</td>\n",
       "      <td>0.023178</td>\n",
       "      <td>-0.003918</td>\n",
       "      <td>-0.022010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MechVent</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mg</th>\n",
       "      <td>0.047530</td>\n",
       "      <td>0.029570</td>\n",
       "      <td>0.042236</td>\n",
       "      <td>0.143433</td>\n",
       "      <td>0.028930</td>\n",
       "      <td>0.299111</td>\n",
       "      <td>0.128935</td>\n",
       "      <td>0.026229</td>\n",
       "      <td>0.158568</td>\n",
       "      <td>-0.068884</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014542</td>\n",
       "      <td>-0.048693</td>\n",
       "      <td>-0.104207</td>\n",
       "      <td>-0.001359</td>\n",
       "      <td>0.042362</td>\n",
       "      <td>-0.094634</td>\n",
       "      <td>0.064238</td>\n",
       "      <td>0.054599</td>\n",
       "      <td>-0.006743</td>\n",
       "      <td>0.061766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIDiasABP</th>\n",
       "      <td>-0.011555</td>\n",
       "      <td>0.023721</td>\n",
       "      <td>-0.000169</td>\n",
       "      <td>-0.264847</td>\n",
       "      <td>0.185396</td>\n",
       "      <td>-0.129948</td>\n",
       "      <td>-0.016910</td>\n",
       "      <td>0.022331</td>\n",
       "      <td>-0.027824</td>\n",
       "      <td>0.406921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009946</td>\n",
       "      <td>0.195174</td>\n",
       "      <td>0.030012</td>\n",
       "      <td>-0.012193</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.154416</td>\n",
       "      <td>-0.086380</td>\n",
       "      <td>0.004604</td>\n",
       "      <td>-0.023172</td>\n",
       "      <td>-0.080454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NIMAP</th>\n",
       "      <td>-0.031432</td>\n",
       "      <td>0.011535</td>\n",
       "      <td>-0.018653</td>\n",
       "      <td>-0.182128</td>\n",
       "      <td>0.199239</td>\n",
       "      <td>-0.117328</td>\n",
       "      <td>-0.043218</td>\n",
       "      <td>0.016719</td>\n",
       "      <td>-0.008492</td>\n",
       "      <td>0.363677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033713</td>\n",
       "      <td>0.338897</td>\n",
       "      <td>0.035853</td>\n",
       "      <td>-0.001113</td>\n",
       "      <td>-0.036129</td>\n",
       "      <td>0.141657</td>\n",
       "      <td>-0.080380</td>\n",
       "      <td>-0.001990</td>\n",
       "      <td>-0.016219</td>\n",
       "      <td>-0.078995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NISysABP</th>\n",
       "      <td>-0.041680</td>\n",
       "      <td>-0.006403</td>\n",
       "      <td>-0.031567</td>\n",
       "      <td>-0.003619</td>\n",
       "      <td>0.172102</td>\n",
       "      <td>-0.039398</td>\n",
       "      <td>-0.046814</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>0.028857</td>\n",
       "      <td>0.182347</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054372</td>\n",
       "      <td>0.398844</td>\n",
       "      <td>0.026189</td>\n",
       "      <td>-0.012545</td>\n",
       "      <td>-0.074585</td>\n",
       "      <td>0.056194</td>\n",
       "      <td>-0.056883</td>\n",
       "      <td>-0.018760</td>\n",
       "      <td>-0.004546</td>\n",
       "      <td>-0.052866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Na</th>\n",
       "      <td>-0.033741</td>\n",
       "      <td>0.021272</td>\n",
       "      <td>0.021510</td>\n",
       "      <td>0.003085</td>\n",
       "      <td>0.031793</td>\n",
       "      <td>0.033020</td>\n",
       "      <td>-0.075726</td>\n",
       "      <td>-0.020135</td>\n",
       "      <td>-0.050621</td>\n",
       "      <td>0.086441</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005721</td>\n",
       "      <td>0.086025</td>\n",
       "      <td>0.012596</td>\n",
       "      <td>-0.002000</td>\n",
       "      <td>-0.029598</td>\n",
       "      <td>0.019323</td>\n",
       "      <td>0.001532</td>\n",
       "      <td>-0.035276</td>\n",
       "      <td>-0.023831</td>\n",
       "      <td>0.021979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PaCO2</th>\n",
       "      <td>-0.038665</td>\n",
       "      <td>-0.078684</td>\n",
       "      <td>-0.089867</td>\n",
       "      <td>-0.023488</td>\n",
       "      <td>0.075239</td>\n",
       "      <td>-0.057482</td>\n",
       "      <td>-0.099564</td>\n",
       "      <td>0.010901</td>\n",
       "      <td>-0.090957</td>\n",
       "      <td>0.001903</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130013</td>\n",
       "      <td>0.019603</td>\n",
       "      <td>0.026584</td>\n",
       "      <td>-0.023453</td>\n",
       "      <td>-0.046353</td>\n",
       "      <td>0.012166</td>\n",
       "      <td>-0.028493</td>\n",
       "      <td>0.147894</td>\n",
       "      <td>-0.004599</td>\n",
       "      <td>-0.075550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PaO2</th>\n",
       "      <td>-0.004341</td>\n",
       "      <td>-0.003155</td>\n",
       "      <td>-0.003046</td>\n",
       "      <td>-0.003788</td>\n",
       "      <td>0.001884</td>\n",
       "      <td>-0.006133</td>\n",
       "      <td>-0.004365</td>\n",
       "      <td>0.002261</td>\n",
       "      <td>-0.007304</td>\n",
       "      <td>-0.001624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>-0.001938</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>-0.002347</td>\n",
       "      <td>-0.002515</td>\n",
       "      <td>-0.002147</td>\n",
       "      <td>-0.003858</td>\n",
       "      <td>-0.003698</td>\n",
       "      <td>-0.000904</td>\n",
       "      <td>-0.008070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Platelets</th>\n",
       "      <td>0.071202</td>\n",
       "      <td>-0.077499</td>\n",
       "      <td>-0.084033</td>\n",
       "      <td>-0.023755</td>\n",
       "      <td>0.019028</td>\n",
       "      <td>-0.034506</td>\n",
       "      <td>-0.146147</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>-0.034072</td>\n",
       "      <td>0.026909</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>-0.002860</td>\n",
       "      <td>-0.019080</td>\n",
       "      <td>0.009234</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.048811</td>\n",
       "      <td>0.254720</td>\n",
       "      <td>-0.032443</td>\n",
       "      <td>0.007590</td>\n",
       "      <td>-0.020178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecordID</th>\n",
       "      <td>0.013645</td>\n",
       "      <td>0.026546</td>\n",
       "      <td>0.018264</td>\n",
       "      <td>-0.019319</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>-0.033135</td>\n",
       "      <td>-0.022028</td>\n",
       "      <td>-0.175844</td>\n",
       "      <td>-0.027901</td>\n",
       "      <td>0.020986</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011660</td>\n",
       "      <td>0.027466</td>\n",
       "      <td>0.028300</td>\n",
       "      <td>0.011042</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.043720</td>\n",
       "      <td>-0.005323</td>\n",
       "      <td>0.022967</td>\n",
       "      <td>0.031021</td>\n",
       "      <td>-0.011570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RespRate</th>\n",
       "      <td>-0.008747</td>\n",
       "      <td>0.019284</td>\n",
       "      <td>0.014621</td>\n",
       "      <td>0.069773</td>\n",
       "      <td>-0.024060</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>-0.017754</td>\n",
       "      <td>-0.009600</td>\n",
       "      <td>-0.013689</td>\n",
       "      <td>-0.002973</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043456</td>\n",
       "      <td>-0.029084</td>\n",
       "      <td>0.014763</td>\n",
       "      <td>0.013639</td>\n",
       "      <td>0.028234</td>\n",
       "      <td>-0.019015</td>\n",
       "      <td>0.066275</td>\n",
       "      <td>-0.043085</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.031718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SaO2</th>\n",
       "      <td>-0.024257</td>\n",
       "      <td>-0.067018</td>\n",
       "      <td>-0.095091</td>\n",
       "      <td>0.021496</td>\n",
       "      <td>0.035633</td>\n",
       "      <td>-0.037919</td>\n",
       "      <td>-0.003182</td>\n",
       "      <td>0.008578</td>\n",
       "      <td>-0.019475</td>\n",
       "      <td>-0.003486</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027539</td>\n",
       "      <td>0.045161</td>\n",
       "      <td>0.009874</td>\n",
       "      <td>-0.016704</td>\n",
       "      <td>0.047396</td>\n",
       "      <td>-0.027766</td>\n",
       "      <td>-0.042075</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>-0.056530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SysABP</th>\n",
       "      <td>-0.052407</td>\n",
       "      <td>-0.050335</td>\n",
       "      <td>-0.053931</td>\n",
       "      <td>0.009608</td>\n",
       "      <td>0.103017</td>\n",
       "      <td>-0.042018</td>\n",
       "      <td>-0.053594</td>\n",
       "      <td>0.011681</td>\n",
       "      <td>-0.030945</td>\n",
       "      <td>0.594665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023584</td>\n",
       "      <td>-0.001503</td>\n",
       "      <td>-0.095888</td>\n",
       "      <td>0.065891</td>\n",
       "      <td>-0.070584</td>\n",
       "      <td>-0.018837</td>\n",
       "      <td>-0.000909</td>\n",
       "      <td>-0.047688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Temp</th>\n",
       "      <td>-0.051107</td>\n",
       "      <td>-0.017507</td>\n",
       "      <td>-0.014374</td>\n",
       "      <td>-0.146972</td>\n",
       "      <td>0.006044</td>\n",
       "      <td>-0.182530</td>\n",
       "      <td>-0.091075</td>\n",
       "      <td>0.014865</td>\n",
       "      <td>-0.108552</td>\n",
       "      <td>0.047105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045161</td>\n",
       "      <td>0.023584</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.005596</td>\n",
       "      <td>0.011998</td>\n",
       "      <td>0.020169</td>\n",
       "      <td>0.037632</td>\n",
       "      <td>0.086922</td>\n",
       "      <td>0.011210</td>\n",
       "      <td>-0.059519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TroponinI</th>\n",
       "      <td>-0.011932</td>\n",
       "      <td>-0.011350</td>\n",
       "      <td>-0.012664</td>\n",
       "      <td>0.043898</td>\n",
       "      <td>0.009577</td>\n",
       "      <td>0.072952</td>\n",
       "      <td>-0.007221</td>\n",
       "      <td>-0.021201</td>\n",
       "      <td>0.034726</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009874</td>\n",
       "      <td>-0.001503</td>\n",
       "      <td>-0.005596</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.016389</td>\n",
       "      <td>-0.016438</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>-0.010348</td>\n",
       "      <td>-0.005872</td>\n",
       "      <td>0.053133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TroponinT</th>\n",
       "      <td>-0.019689</td>\n",
       "      <td>0.037490</td>\n",
       "      <td>0.081825</td>\n",
       "      <td>0.051547</td>\n",
       "      <td>0.039915</td>\n",
       "      <td>0.042128</td>\n",
       "      <td>-0.016851</td>\n",
       "      <td>0.036640</td>\n",
       "      <td>0.047885</td>\n",
       "      <td>0.009634</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016704</td>\n",
       "      <td>-0.095888</td>\n",
       "      <td>0.011998</td>\n",
       "      <td>-0.016389</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.017428</td>\n",
       "      <td>0.033838</td>\n",
       "      <td>-0.027898</td>\n",
       "      <td>-0.006005</td>\n",
       "      <td>0.034866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Urine</th>\n",
       "      <td>-0.040027</td>\n",
       "      <td>-0.048773</td>\n",
       "      <td>-0.064821</td>\n",
       "      <td>-0.255105</td>\n",
       "      <td>0.102044</td>\n",
       "      <td>-0.195167</td>\n",
       "      <td>-0.076323</td>\n",
       "      <td>0.013926</td>\n",
       "      <td>-0.162525</td>\n",
       "      <td>0.119911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047396</td>\n",
       "      <td>0.065891</td>\n",
       "      <td>0.020169</td>\n",
       "      <td>-0.016438</td>\n",
       "      <td>-0.017428</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.101386</td>\n",
       "      <td>0.044751</td>\n",
       "      <td>-0.006337</td>\n",
       "      <td>-0.120881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WBC</th>\n",
       "      <td>0.085952</td>\n",
       "      <td>0.013325</td>\n",
       "      <td>0.032749</td>\n",
       "      <td>0.034414</td>\n",
       "      <td>-0.099285</td>\n",
       "      <td>0.101356</td>\n",
       "      <td>0.018515</td>\n",
       "      <td>-0.010553</td>\n",
       "      <td>0.032108</td>\n",
       "      <td>-0.019035</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027766</td>\n",
       "      <td>-0.070584</td>\n",
       "      <td>0.037632</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.033838</td>\n",
       "      <td>-0.101386</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.040306</td>\n",
       "      <td>-0.002136</td>\n",
       "      <td>0.094936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Weight</th>\n",
       "      <td>-0.021914</td>\n",
       "      <td>-0.001541</td>\n",
       "      <td>0.008551</td>\n",
       "      <td>-0.177945</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.079346</td>\n",
       "      <td>0.033972</td>\n",
       "      <td>-0.012247</td>\n",
       "      <td>0.091286</td>\n",
       "      <td>0.045176</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042075</td>\n",
       "      <td>-0.018837</td>\n",
       "      <td>0.086922</td>\n",
       "      <td>-0.010348</td>\n",
       "      <td>-0.027898</td>\n",
       "      <td>0.044751</td>\n",
       "      <td>0.040306</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.011871</td>\n",
       "      <td>-0.054443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pH</th>\n",
       "      <td>-0.005073</td>\n",
       "      <td>-0.004561</td>\n",
       "      <td>-0.001068</td>\n",
       "      <td>0.025433</td>\n",
       "      <td>0.007397</td>\n",
       "      <td>-0.007620</td>\n",
       "      <td>-0.006371</td>\n",
       "      <td>-0.004304</td>\n",
       "      <td>0.006364</td>\n",
       "      <td>-0.011028</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002558</td>\n",
       "      <td>-0.000909</td>\n",
       "      <td>0.011210</td>\n",
       "      <td>-0.005872</td>\n",
       "      <td>-0.006005</td>\n",
       "      <td>-0.006337</td>\n",
       "      <td>-0.002136</td>\n",
       "      <td>-0.011871</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>In-hospital_death</th>\n",
       "      <td>0.115577</td>\n",
       "      <td>0.070992</td>\n",
       "      <td>0.108484</td>\n",
       "      <td>0.130701</td>\n",
       "      <td>-0.126925</td>\n",
       "      <td>0.223369</td>\n",
       "      <td>0.174017</td>\n",
       "      <td>-0.008578</td>\n",
       "      <td>0.117615</td>\n",
       "      <td>-0.050506</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056530</td>\n",
       "      <td>-0.047688</td>\n",
       "      <td>-0.059519</td>\n",
       "      <td>0.053133</td>\n",
       "      <td>0.034866</td>\n",
       "      <td>-0.120881</td>\n",
       "      <td>0.094936</td>\n",
       "      <td>-0.054443</td>\n",
       "      <td>0.024961</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ALP       ALT       AST       Age   Albumin       BUN  \\\n",
       "ALP                1.000000  0.114850  0.155750  0.000879 -0.137771  0.155416   \n",
       "ALT                0.114850  1.000000  0.858741 -0.112012 -0.009850  0.038541   \n",
       "AST                0.155750  0.858741  1.000000 -0.088649 -0.037277  0.051244   \n",
       "Age                0.000879 -0.112012 -0.088649  1.000000 -0.036231  0.228768   \n",
       "Albumin           -0.137771 -0.009850 -0.037277 -0.036231  1.000000 -0.100987   \n",
       "BUN                0.155416  0.038541  0.051244  0.228768 -0.100987  1.000000   \n",
       "Bilirubin          0.240297  0.109332  0.127767 -0.063837 -0.086068  0.185473   \n",
       "Cholesterol       -0.006795 -0.024351 -0.020751 -0.010103  0.058119 -0.014453   \n",
       "Creatinine         0.131899  0.077210  0.092024  0.033369 -0.030867  0.683278   \n",
       "DiasABP           -0.035320  0.024430  0.030425 -0.263634  0.077583 -0.119703   \n",
       "FiO2              -0.003474 -0.003840 -0.003814 -0.011746  0.001028 -0.009474   \n",
       "GCS                0.020718 -0.073180 -0.123846  0.027736  0.144026 -0.031887   \n",
       "Gender            -0.002758 -0.002251 -0.002259 -0.020055 -0.000094 -0.004939   \n",
       "Glucose            0.014560  0.049459  0.076040  0.057239  0.030054  0.126179   \n",
       "HCO3              -0.095050 -0.088142 -0.117626  0.008126  0.182131 -0.236730   \n",
       "HCT               -0.010624  0.047127  0.022552 -0.065288  0.228917 -0.096426   \n",
       "HR                 0.026164  0.091215  0.104572 -0.246909 -0.137857 -0.060862   \n",
       "Height            -0.014689  0.012009  0.016882 -0.088042  0.018550  0.023661   \n",
       "ICUType           -0.002739 -0.002238 -0.002260  0.021302 -0.000138 -0.004988   \n",
       "K                  0.018410 -0.004501  0.031697  0.081105 -0.049365  0.264277   \n",
       "Lactate            0.047983  0.193083  0.282596 -0.018507 -0.066734  0.037174   \n",
       "MAP               -0.017456  0.021525 -0.000306 -0.114144  0.091947 -0.080205   \n",
       "MechVent                NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "Mg                 0.047530  0.029570  0.042236  0.143433  0.028930  0.299111   \n",
       "NIDiasABP         -0.011555  0.023721 -0.000169 -0.264847  0.185396 -0.129948   \n",
       "NIMAP             -0.031432  0.011535 -0.018653 -0.182128  0.199239 -0.117328   \n",
       "NISysABP          -0.041680 -0.006403 -0.031567 -0.003619  0.172102 -0.039398   \n",
       "Na                -0.033741  0.021272  0.021510  0.003085  0.031793  0.033020   \n",
       "PaCO2             -0.038665 -0.078684 -0.089867 -0.023488  0.075239 -0.057482   \n",
       "PaO2              -0.004341 -0.003155 -0.003046 -0.003788  0.001884 -0.006133   \n",
       "Platelets          0.071202 -0.077499 -0.084033 -0.023755  0.019028 -0.034506   \n",
       "RecordID           0.013645  0.026546  0.018264 -0.019319  0.019584 -0.033135   \n",
       "RespRate          -0.008747  0.019284  0.014621  0.069773 -0.024060  0.000831   \n",
       "SaO2              -0.024257 -0.067018 -0.095091  0.021496  0.035633 -0.037919   \n",
       "SysABP            -0.052407 -0.050335 -0.053931  0.009608  0.103017 -0.042018   \n",
       "Temp              -0.051107 -0.017507 -0.014374 -0.146972  0.006044 -0.182530   \n",
       "TroponinI         -0.011932 -0.011350 -0.012664  0.043898  0.009577  0.072952   \n",
       "TroponinT         -0.019689  0.037490  0.081825  0.051547  0.039915  0.042128   \n",
       "Urine             -0.040027 -0.048773 -0.064821 -0.255105  0.102044 -0.195167   \n",
       "WBC                0.085952  0.013325  0.032749  0.034414 -0.099285  0.101356   \n",
       "Weight            -0.021914 -0.001541  0.008551 -0.177945  0.000732  0.079346   \n",
       "pH                -0.005073 -0.004561 -0.001068  0.025433  0.007397 -0.007620   \n",
       "In-hospital_death  0.115577  0.070992  0.108484  0.130701 -0.126925  0.223369   \n",
       "\n",
       "                   Bilirubin  Cholesterol  Creatinine   DiasABP  ...  \\\n",
       "ALP                 0.240297    -0.006795    0.131899 -0.035320  ...   \n",
       "ALT                 0.109332    -0.024351    0.077210  0.024430  ...   \n",
       "AST                 0.127767    -0.020751    0.092024  0.030425  ...   \n",
       "Age                -0.063837    -0.010103    0.033369 -0.263634  ...   \n",
       "Albumin            -0.086068     0.058119   -0.030867  0.077583  ...   \n",
       "BUN                 0.185473    -0.014453    0.683278 -0.119703  ...   \n",
       "Bilirubin           1.000000    -0.017119    0.140630 -0.031563  ...   \n",
       "Cholesterol        -0.017119     1.000000   -0.023809  0.072380  ...   \n",
       "Creatinine          0.140630    -0.023809    1.000000 -0.072456  ...   \n",
       "DiasABP            -0.031563     0.072380   -0.072456  1.000000  ...   \n",
       "FiO2               -0.004779    -0.299331   -0.008805 -0.169800  ...   \n",
       "GCS                -0.042079     0.010350   -0.021087 -0.052003  ...   \n",
       "Gender             -0.002749     0.001810   -0.004057 -0.059151  ...   \n",
       "Glucose            -0.029639     0.039647    0.037075  0.009471  ...   \n",
       "HCO3               -0.132563     0.020805   -0.237834  0.029013  ...   \n",
       "HCT                -0.040429     0.074143   -0.057180  0.199300  ...   \n",
       "HR                  0.019632    -0.040332   -0.032015  0.136714  ...   \n",
       "Height              0.012634     0.006758    0.047051  0.046366  ...   \n",
       "ICUType            -0.002727     0.001792   -0.004856 -0.064856  ...   \n",
       "K                  -0.020082     0.012194    0.285873 -0.108060  ...   \n",
       "Lactate             0.103735     0.002234    0.047987 -0.041495  ...   \n",
       "MAP                -0.032284     0.027633   -0.054207  0.450196  ...   \n",
       "MechVent                 NaN          NaN         NaN       NaN  ...   \n",
       "Mg                  0.128935     0.026229    0.158568 -0.068884  ...   \n",
       "NIDiasABP          -0.016910     0.022331   -0.027824  0.406921  ...   \n",
       "NIMAP              -0.043218     0.016719   -0.008492  0.363677  ...   \n",
       "NISysABP           -0.046814     0.002373    0.028857  0.182347  ...   \n",
       "Na                 -0.075726    -0.020135   -0.050621  0.086441  ...   \n",
       "PaCO2              -0.099564     0.010901   -0.090957  0.001903  ...   \n",
       "PaO2               -0.004365     0.002261   -0.007304 -0.001624  ...   \n",
       "Platelets          -0.146147     0.003008   -0.034072  0.026909  ...   \n",
       "RecordID           -0.022028    -0.175844   -0.027901  0.020986  ...   \n",
       "RespRate           -0.017754    -0.009600   -0.013689 -0.002973  ...   \n",
       "SaO2               -0.003182     0.008578   -0.019475 -0.003486  ...   \n",
       "SysABP             -0.053594     0.011681   -0.030945  0.594665  ...   \n",
       "Temp               -0.091075     0.014865   -0.108552  0.047105  ...   \n",
       "TroponinI          -0.007221    -0.021201    0.034726  0.000694  ...   \n",
       "TroponinT          -0.016851     0.036640    0.047885  0.009634  ...   \n",
       "Urine              -0.076323     0.013926   -0.162525  0.119911  ...   \n",
       "WBC                 0.018515    -0.010553    0.032108 -0.019035  ...   \n",
       "Weight              0.033972    -0.012247    0.091286  0.045176  ...   \n",
       "pH                 -0.006371    -0.004304    0.006364 -0.011028  ...   \n",
       "In-hospital_death   0.174017    -0.008578    0.117615 -0.050506  ...   \n",
       "\n",
       "                       SaO2    SysABP      Temp  TroponinI  TroponinT  \\\n",
       "ALP               -0.024257 -0.052407 -0.051107  -0.011932  -0.019689   \n",
       "ALT               -0.067018 -0.050335 -0.017507  -0.011350   0.037490   \n",
       "AST               -0.095091 -0.053931 -0.014374  -0.012664   0.081825   \n",
       "Age                0.021496  0.009608 -0.146972   0.043898   0.051547   \n",
       "Albumin            0.035633  0.103017  0.006044   0.009577   0.039915   \n",
       "BUN               -0.037919 -0.042018 -0.182530   0.072952   0.042128   \n",
       "Bilirubin         -0.003182 -0.053594 -0.091075  -0.007221  -0.016851   \n",
       "Cholesterol        0.008578  0.011681  0.014865  -0.021201   0.036640   \n",
       "Creatinine        -0.019475 -0.030945 -0.108552   0.034726   0.047885   \n",
       "DiasABP           -0.003486  0.594665  0.047105   0.000694   0.009634   \n",
       "FiO2               0.003533 -0.001053  0.001465  -0.002287  -0.004453   \n",
       "GCS                0.031215 -0.004390 -0.182994  -0.015576  -0.024584   \n",
       "Gender             0.002127 -0.001196  0.000280  -0.001756  -0.002442   \n",
       "Glucose            0.002018  0.035862 -0.033763   0.031719   0.043126   \n",
       "HCO3              -0.048361  0.097960  0.064890  -0.021523  -0.045145   \n",
       "HCT               -0.049210  0.071777 -0.032963   0.002804   0.078635   \n",
       "HR                -0.042553 -0.152790  0.205528  -0.007784  -0.013808   \n",
       "Height            -0.018500  0.003668  0.020027   0.001599   0.006398   \n",
       "ICUType            0.002142 -0.001107  0.000304  -0.001787  -0.002547   \n",
       "K                 -0.038602 -0.104015 -0.068384   0.003915   0.013367   \n",
       "Lactate           -0.052907 -0.066719 -0.033017  -0.007629   0.019889   \n",
       "MAP                0.026236  0.346110  0.034847   0.001332  -0.020526   \n",
       "MechVent                NaN       NaN       NaN        NaN        NaN   \n",
       "Mg                -0.014542 -0.048693 -0.104207  -0.001359   0.042362   \n",
       "NIDiasABP          0.009946  0.195174  0.030012  -0.012193   0.000586   \n",
       "NIMAP              0.033713  0.338897  0.035853  -0.001113  -0.036129   \n",
       "NISysABP           0.054372  0.398844  0.026189  -0.012545  -0.074585   \n",
       "Na                -0.005721  0.086025  0.012596  -0.002000  -0.029598   \n",
       "PaCO2             -0.130013  0.019603  0.026584  -0.023453  -0.046353   \n",
       "PaO2               0.007321 -0.001938  0.000470  -0.002347  -0.002515   \n",
       "Platelets          0.011900 -0.002860 -0.019080   0.009234   0.001186   \n",
       "RecordID          -0.011660  0.027466  0.028300   0.011042   0.002464   \n",
       "RespRate          -0.043456 -0.029084  0.014763   0.013639   0.028234   \n",
       "SaO2               1.000000  0.027539  0.045161   0.009874  -0.016704   \n",
       "SysABP             0.027539  1.000000  0.023584  -0.001503  -0.095888   \n",
       "Temp               0.045161  0.023584  1.000000  -0.005596   0.011998   \n",
       "TroponinI          0.009874 -0.001503 -0.005596   1.000000  -0.016389   \n",
       "TroponinT         -0.016704 -0.095888  0.011998  -0.016389   1.000000   \n",
       "Urine              0.047396  0.065891  0.020169  -0.016438  -0.017428   \n",
       "WBC               -0.027766 -0.070584  0.037632   0.001771   0.033838   \n",
       "Weight            -0.042075 -0.018837  0.086922  -0.010348  -0.027898   \n",
       "pH                 0.002558 -0.000909  0.011210  -0.005872  -0.006005   \n",
       "In-hospital_death -0.056530 -0.047688 -0.059519   0.053133   0.034866   \n",
       "\n",
       "                      Urine       WBC    Weight        pH  In-hospital_death  \n",
       "ALP               -0.040027  0.085952 -0.021914 -0.005073           0.115577  \n",
       "ALT               -0.048773  0.013325 -0.001541 -0.004561           0.070992  \n",
       "AST               -0.064821  0.032749  0.008551 -0.001068           0.108484  \n",
       "Age               -0.255105  0.034414 -0.177945  0.025433           0.130701  \n",
       "Albumin            0.102044 -0.099285  0.000732  0.007397          -0.126925  \n",
       "BUN               -0.195167  0.101356  0.079346 -0.007620           0.223369  \n",
       "Bilirubin         -0.076323  0.018515  0.033972 -0.006371           0.174017  \n",
       "Cholesterol        0.013926 -0.010553 -0.012247 -0.004304          -0.008578  \n",
       "Creatinine        -0.162525  0.032108  0.091286  0.006364           0.117615  \n",
       "DiasABP            0.119911 -0.019035  0.045176 -0.011028          -0.050506  \n",
       "FiO2              -0.004723 -0.004137 -0.003293 -0.000945          -0.010986  \n",
       "GCS                0.160777 -0.107853 -0.052356  0.013951          -0.254104  \n",
       "Gender            -0.002989 -0.002588 -0.001816 -0.000540          -0.006346  \n",
       "Glucose           -0.020630  0.050115  0.066428  0.001707           0.105764  \n",
       "HCO3               0.101372 -0.123303  0.075300 -0.016808          -0.129574  \n",
       "HCT                0.099207  0.044376  0.040221  0.001903          -0.009584  \n",
       "HR                -0.028292  0.114941  0.020675  0.014498           0.073561  \n",
       "Height             0.025509 -0.006818  0.124226 -0.011014          -0.012456  \n",
       "ICUType           -0.003018 -0.002582 -0.001878 -0.000546          -0.006314  \n",
       "K                 -0.109000  0.067543  0.145366  0.010682           0.018713  \n",
       "Lactate           -0.038360  0.046109  0.014322  0.000496           0.124184  \n",
       "MAP                0.079936 -0.039635  0.023178 -0.003918          -0.022010  \n",
       "MechVent                NaN       NaN       NaN       NaN                NaN  \n",
       "Mg                -0.094634  0.064238  0.054599 -0.006743           0.061766  \n",
       "NIDiasABP          0.154416 -0.086380  0.004604 -0.023172          -0.080454  \n",
       "NIMAP              0.141657 -0.080380 -0.001990 -0.016219          -0.078995  \n",
       "NISysABP           0.056194 -0.056883 -0.018760 -0.004546          -0.052866  \n",
       "Na                 0.019323  0.001532 -0.035276 -0.023831           0.021979  \n",
       "PaCO2              0.012166 -0.028493  0.147894 -0.004599          -0.075550  \n",
       "PaO2              -0.002147 -0.003858 -0.003698 -0.000904          -0.008070  \n",
       "Platelets          0.048811  0.254720 -0.032443  0.007590          -0.020178  \n",
       "RecordID           0.043720 -0.005323  0.022967  0.031021          -0.011570  \n",
       "RespRate          -0.019015  0.066275 -0.043085  0.001242           0.031718  \n",
       "SaO2               0.047396 -0.027766 -0.042075  0.002558          -0.056530  \n",
       "SysABP             0.065891 -0.070584 -0.018837 -0.000909          -0.047688  \n",
       "Temp               0.020169  0.037632  0.086922  0.011210          -0.059519  \n",
       "TroponinI         -0.016438  0.001771 -0.010348 -0.005872           0.053133  \n",
       "TroponinT         -0.017428  0.033838 -0.027898 -0.006005           0.034866  \n",
       "Urine              1.000000 -0.101386  0.044751 -0.006337          -0.120881  \n",
       "WBC               -0.101386  1.000000  0.040306 -0.002136           0.094936  \n",
       "Weight             0.044751  0.040306  1.000000 -0.011871          -0.054443  \n",
       "pH                -0.006337 -0.002136 -0.011871  1.000000           0.024961  \n",
       "In-hospital_death -0.120881  0.094936 -0.054443  0.024961           1.000000  \n",
       "\n",
       "[43 rows x 43 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = merged_data.corr()\n",
    "corr_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the parameters which are more preferable for training\n",
    "\n",
    "\n",
    "in correlation matrix we found whose value positive is more preferable so,we filter the parameter names in below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALP                  0.115577\n",
       "ALT                  0.070992\n",
       "AST                  0.108484\n",
       "Age                  0.130701\n",
       "BUN                  0.223369\n",
       "Bilirubin            0.174017\n",
       "Creatinine           0.117615\n",
       "Glucose              0.105764\n",
       "HR                   0.073561\n",
       "K                    0.018713\n",
       "Lactate              0.124184\n",
       "Mg                   0.061766\n",
       "Na                   0.021979\n",
       "RespRate             0.031718\n",
       "TroponinI            0.053133\n",
       "TroponinT            0.034866\n",
       "WBC                  0.094936\n",
       "pH                   0.024961\n",
       "In-hospital_death    1.000000\n",
       "Name: In-hospital_death, dtype: float64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_dead =corr_matrix['In-hospital_death']\n",
    "corr_dead[corr_dead>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ALP                  0.115577\n",
       "ALT                  0.070992\n",
       "AST                  0.108484\n",
       "Age                  0.130701\n",
       "BUN                  0.223369\n",
       "Bilirubin            0.174017\n",
       "Creatinine           0.117615\n",
       "Glucose              0.105764\n",
       "HR                   0.073561\n",
       "K                    0.018713\n",
       "Lactate              0.124184\n",
       "Mg                   0.061766\n",
       "Na                   0.021979\n",
       "RespRate             0.031718\n",
       "TroponinI            0.053133\n",
       "TroponinT            0.034866\n",
       "WBC                  0.094936\n",
       "pH                   0.024961\n",
       "In-hospital_death    1.000000\n",
       "Name: In-hospital_death, dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_dead[corr_dead>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALP',\n",
       " 'ALT',\n",
       " 'AST',\n",
       " 'Age',\n",
       " 'BUN',\n",
       " 'Bilirubin',\n",
       " 'Creatinine',\n",
       " 'Glucose',\n",
       " 'HR',\n",
       " 'K',\n",
       " 'Lactate',\n",
       " 'Mg',\n",
       " 'Na',\n",
       " 'RespRate',\n",
       " 'TroponinI',\n",
       " 'TroponinT',\n",
       " 'WBC',\n",
       " 'pH',\n",
       " 'In-hospital_death']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_dead[corr_dead>0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Age</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>HR</th>\n",
       "      <th>K</th>\n",
       "      <th>Lactate</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Na</th>\n",
       "      <th>RespRate</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>WBC</th>\n",
       "      <th>pH</th>\n",
       "      <th>In-hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>54</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>70.810811</td>\n",
       "      <td>4.20</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>136.500000</td>\n",
       "      <td>17.428571</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>7.387273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>76</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>125.500000</td>\n",
       "      <td>80.794118</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>11.266667</td>\n",
       "      <td>7.395000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>199.5</td>\n",
       "      <td>44</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>134.333333</td>\n",
       "      <td>83.759259</td>\n",
       "      <td>4.26</td>\n",
       "      <td>1.366667</td>\n",
       "      <td>1.720000</td>\n",
       "      <td>138.333333</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>7.495000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>68</td>\n",
       "      <td>17.666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>117.333333</td>\n",
       "      <td>70.983333</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>139.333333</td>\n",
       "      <td>15.457627</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>7.387273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>88</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.500000</td>\n",
       "      <td>74.958333</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>1.550000</td>\n",
       "      <td>139.500000</td>\n",
       "      <td>19.166667</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>7.387273</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ALP   ALT    AST  Age        BUN  Bilirubin  Creatinine     Glucose  \\\n",
       "0   77.0  31.0   46.0   54  10.500000        0.7    0.750000  160.000000   \n",
       "1   77.0  31.0   46.0   76  18.333333        0.7    1.100000  125.500000   \n",
       "2  116.0  83.0  199.5   44   4.666667        2.9    0.333333  134.333333   \n",
       "3  105.0  12.0   15.0   68  17.666667        0.2    0.766667  117.333333   \n",
       "4   77.0  31.0   46.0   88  35.000000        0.7    1.000000  102.500000   \n",
       "\n",
       "          HR     K   Lactate        Mg          Na   RespRate  TroponinI  \\\n",
       "0  70.810811  4.20  1.900000  1.700000  136.500000  17.428571        2.1   \n",
       "1  80.794118  3.90  1.900000  2.300000  137.000000  19.000000        2.1   \n",
       "2  83.759259  4.26  1.366667  1.720000  138.333333  19.000000        2.1   \n",
       "3  70.983333  4.00  1.900000  2.033333  139.333333  15.457627        2.1   \n",
       "4  74.958333  4.32  1.900000  1.550000  139.500000  19.166667        2.1   \n",
       "\n",
       "   TroponinT        WBC        pH  In-hospital_death  \n",
       "0       0.14  10.300000  7.387273                  0  \n",
       "1       0.14  11.266667  7.395000                  0  \n",
       "2       0.14   4.700000  7.495000                  0  \n",
       "3       0.14   9.400000  7.387273                  0  \n",
       "4       0.14   4.300000  7.387273                  0  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data=merged_data[corr_dead[corr_dead>0].index.to_list()]\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets clean the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `StandardScaler` in scikit-learn is a tool used for standardizing features by removing the mean and scaling to unit variance. Let's break down the benefits of using `StandardScaler` in an easy-to-understand manner:\n",
    "\n",
    "1. **Mean Removal**: It centers the feature columns around zero by removing the mean. This is important because many machine learning algorithms assume that the features are centered around zero.\n",
    "\n",
    "2. **Unit Variance Scaling**: It scales the feature columns to have a standard deviation of 1. This is crucial because features with different scales might lead the machine learning algorithm to assign more weight to features with larger scales, potentially causing issues in the model's performance.\n",
    "\n",
    "   Imagine you have a feature like \"Income\" ranging from 20,000 to 200,000 and another feature like \"Age\" ranging from 0 to 100. Without scaling, the algorithm might give more importance to \"Income\" just because its values are larger, even if \"Age\" is equally important.\n",
    "\n",
    "3. **Makes Optimization Easier**: Many optimization algorithms (e.g., gradient descent) work faster and are more stable when features are on a similar scale. Scaling helps in reaching the optimal solution more quickly.\n",
    "\n",
    "4. **Maintains Relationships Between Features**: It ensures that the relative relationships (e.g., correlations) between features remain the same after scaling. Scaling doesn't change the relationships; it just puts them on a consistent scale.\n",
    "\n",
    "In summary, `StandardScaler` is a preprocessing step that helps in preparing the data for machine learning models, ensuring fair treatment of all features and facilitating a smoother optimization process during model training.\n",
    "\n",
    "\n",
    "In more easy manner-\n",
    "Of course! Imagine you have a bunch of different things to eat, like fruits and snacks. But these things come in different sizes and shapes. Some are big, some are small. It's like comparing apples and oranges, literally!\n",
    "\n",
    "Now, let's say you want to compare them in a fair way. You want to be able to say which one you like the most, not just because it's bigger or smaller, but because of its own taste. To do that, you need to make sure they're all in the same size.\n",
    "\n",
    "The StandardScaler is like a magical machine that takes these fruits and snacks and makes them all the same size, just like if you were comparing all fruits to be the same size as an apple. This way, when you say which one you like the most, it's based on taste, not size.\n",
    "\n",
    "In the world of computers and numbers (which is like a big playground for math), we have numbers that are like those fruits and snacks. They come in different sizes. StandardScaler helps us make them all the same size, so when we use them in a special math game called a machine learning game, they play fair and everyone gets a fair chance to show how important they are.\n",
    "\n",
    "So, it's like making sure all our fruits and snacks are the same size before we decide which one is the yummiest! 🍎🍊🍇🍪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = new_data['In-hospital_death']\n",
    "x = new_data.drop('In-hospital_death',axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3999,)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>Age</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Bilirubin</th>\n",
       "      <th>Creatinine</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>HR</th>\n",
       "      <th>K</th>\n",
       "      <th>Lactate</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Na</th>\n",
       "      <th>RespRate</th>\n",
       "      <th>TroponinI</th>\n",
       "      <th>TroponinT</th>\n",
       "      <th>WBC</th>\n",
       "      <th>pH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>54</td>\n",
       "      <td>10.500000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>160.000000</td>\n",
       "      <td>70.810811</td>\n",
       "      <td>4.20</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>136.500000</td>\n",
       "      <td>17.428571</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>10.300000</td>\n",
       "      <td>7.387273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>76</td>\n",
       "      <td>18.333333</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>125.500000</td>\n",
       "      <td>80.794118</td>\n",
       "      <td>3.90</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>2.300000</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>11.266667</td>\n",
       "      <td>7.395000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>199.5</td>\n",
       "      <td>44</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>2.9</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>134.333333</td>\n",
       "      <td>83.759259</td>\n",
       "      <td>4.26</td>\n",
       "      <td>1.366667</td>\n",
       "      <td>1.720000</td>\n",
       "      <td>138.333333</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>4.700000</td>\n",
       "      <td>7.495000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>68</td>\n",
       "      <td>17.666667</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>117.333333</td>\n",
       "      <td>70.983333</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>2.033333</td>\n",
       "      <td>139.333333</td>\n",
       "      <td>15.457627</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>7.387273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>88</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>102.500000</td>\n",
       "      <td>74.958333</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>1.550000</td>\n",
       "      <td>139.500000</td>\n",
       "      <td>19.166667</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>7.387273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ALP   ALT    AST  Age        BUN  Bilirubin  Creatinine     Glucose  \\\n",
       "0   77.0  31.0   46.0   54  10.500000        0.7    0.750000  160.000000   \n",
       "1   77.0  31.0   46.0   76  18.333333        0.7    1.100000  125.500000   \n",
       "2  116.0  83.0  199.5   44   4.666667        2.9    0.333333  134.333333   \n",
       "3  105.0  12.0   15.0   68  17.666667        0.2    0.766667  117.333333   \n",
       "4   77.0  31.0   46.0   88  35.000000        0.7    1.000000  102.500000   \n",
       "\n",
       "          HR     K   Lactate        Mg          Na   RespRate  TroponinI  \\\n",
       "0  70.810811  4.20  1.900000  1.700000  136.500000  17.428571        2.1   \n",
       "1  80.794118  3.90  1.900000  2.300000  137.000000  19.000000        2.1   \n",
       "2  83.759259  4.26  1.366667  1.720000  138.333333  19.000000        2.1   \n",
       "3  70.983333  4.00  1.900000  2.033333  139.333333  15.457627        2.1   \n",
       "4  74.958333  4.32  1.900000  1.550000  139.500000  19.166667        2.1   \n",
       "\n",
       "   TroponinT        WBC        pH  \n",
       "0       0.14  10.300000  7.387273  \n",
       "1       0.14  11.266667  7.395000  \n",
       "2       0.14   4.700000  7.495000  \n",
       "3       0.14   9.400000  7.387273  \n",
       "4       0.14   4.300000  7.387273  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.17417451, -0.14209875, -0.14264578, -0.5835427 , -0.72627589,\n",
       "        -0.17444244, -0.4358424 ,  0.57376214, -1.12117228,  0.12163336,\n",
       "        -0.13701969, -1.04323174, -0.58266576, -0.86543014, -0.11110942,\n",
       "        -0.15467383, -0.34353755, -0.03402444]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "transformed_data = sc.fit_transform(x)\n",
    "transformed_data[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MinMaxScaler\n",
    "\n",
    "Sure, let's explain Min-Max Scaler in a simple way!\n",
    "\n",
    "Imagine you have a collection of toys, like toy cars and toy dolls. Each toy has a different height and width. Now, let's say you want to play with these toys in a dollhouse where the rooms are of a certain size.\n",
    "\n",
    "The Min-Max Scaler is like a magic machine that helps you resize your toys in a way that they all fit nicely into the rooms of the dollhouse. It adjusts the size of each toy, making sure they all fit comfortably.\n",
    "\n",
    "In the world of numbers and data (which is like a big puzzle), we have numbers that are like those toys with different sizes. Min-Max Scaler helps us resize these numbers so they all fit nicely in a specific range, like from 0 to 1.\n",
    "\n",
    "Why is this useful? Well, in some games or puzzles, we want all our numbers to be in a certain range so they can play nicely together, just like the toys fitting into the dollhouse rooms. Min-Max Scaler helps us achieve this fair play by resizing the numbers to fit within the desired range.\n",
    "\n",
    "So, it's like making sure our toys fit nicely in the dollhouse rooms, and Min-Max Scaler helps us do the same with our numbers! 🏠🚗🎎\n",
    "\n",
    "\n",
    "#### Technical-\n",
    "\n",
    "Absolutely! Let's delve a bit more into the technical details of Min-Max Scaler.\n",
    "\n",
    "Min-Max Scaler is a technique used in data preprocessing, specifically for feature scaling, in the field of machine learning and data analysis. Its purpose is to transform the features (columns) of a dataset so that they fall within a specified range, typically [0, 1]. The formula to achieve this scaling for each feature \\(X\\) is:\n",
    "\n",
    "\\[X_{\\text{scaled}} = \\frac{X - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}}\\]\n",
    "\n",
    "where:\n",
    "- \\(X\\) is an original value of a feature,\n",
    "- \\(X_{\\text{min}}\\) is the minimum value of that feature in the dataset,\n",
    "- \\(X_{\\text{max}}\\) is the maximum value of that feature in the dataset.\n",
    "\n",
    "Here's a breakdown:\n",
    "\n",
    "- It subtracts the minimum value (\\(X_{\\text{min}}\\)) of the feature from each value, so the minimum value becomes 0.\n",
    "- Then, it divides by the range of the feature (\\(X_{\\text{max}} - X_{\\text{min}}\\)), so the maximum value of the feature becomes 1.\n",
    "\n",
    "This transformation is particularly useful when you want to ensure that each feature contributes equally to the computation or analysis, especially in cases where the features have different units or scales. It's commonly applied to features that need to be on a similar scale, but not necessarily in a specific statistical distribution.\n",
    "\n",
    "In simpler terms, Min-Max Scaler helps in resizing the features so that they all fit nicely in a range, like making sure all your toys fit nicely in the dollhouse rooms (the desired range). This helps in fair comparisons and computations in machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "transformed_data = scaler.fit_transform(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.044510</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>0.002552</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.048937</td>\n",
       "      <td>0.012968</td>\n",
       "      <td>0.033831</td>\n",
       "      <td>0.265339</td>\n",
       "      <td>0.502890</td>\n",
       "      <td>0.125926</td>\n",
       "      <td>0.017730</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.471402</td>\n",
       "      <td>0.236506</td>\n",
       "      <td>0.03681</td>\n",
       "      <td>0.00541</td>\n",
       "      <td>0.074380</td>\n",
       "      <td>0.008801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.044510</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>0.002552</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.095403</td>\n",
       "      <td>0.012968</td>\n",
       "      <td>0.055360</td>\n",
       "      <td>0.182869</td>\n",
       "      <td>0.576927</td>\n",
       "      <td>0.103704</td>\n",
       "      <td>0.017730</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.480830</td>\n",
       "      <td>0.290485</td>\n",
       "      <td>0.03681</td>\n",
       "      <td>0.00541</td>\n",
       "      <td>0.081429</td>\n",
       "      <td>0.008864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.071217</td>\n",
       "      <td>0.008752</td>\n",
       "      <td>0.012345</td>\n",
       "      <td>0.386667</td>\n",
       "      <td>0.014335</td>\n",
       "      <td>0.060519</td>\n",
       "      <td>0.008202</td>\n",
       "      <td>0.203984</td>\n",
       "      <td>0.598917</td>\n",
       "      <td>0.130370</td>\n",
       "      <td>0.011426</td>\n",
       "      <td>0.106897</td>\n",
       "      <td>0.505971</td>\n",
       "      <td>0.290485</td>\n",
       "      <td>0.03681</td>\n",
       "      <td>0.00541</td>\n",
       "      <td>0.033544</td>\n",
       "      <td>0.009682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.063684</td>\n",
       "      <td>0.000985</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.706667</td>\n",
       "      <td>0.091448</td>\n",
       "      <td>0.002161</td>\n",
       "      <td>0.034856</td>\n",
       "      <td>0.163347</td>\n",
       "      <td>0.504170</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.017730</td>\n",
       "      <td>0.160920</td>\n",
       "      <td>0.524827</td>\n",
       "      <td>0.168803</td>\n",
       "      <td>0.03681</td>\n",
       "      <td>0.00541</td>\n",
       "      <td>0.067817</td>\n",
       "      <td>0.008801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.044510</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>0.002552</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.194266</td>\n",
       "      <td>0.012968</td>\n",
       "      <td>0.049209</td>\n",
       "      <td>0.127888</td>\n",
       "      <td>0.533649</td>\n",
       "      <td>0.134815</td>\n",
       "      <td>0.017730</td>\n",
       "      <td>0.077586</td>\n",
       "      <td>0.527970</td>\n",
       "      <td>0.296210</td>\n",
       "      <td>0.03681</td>\n",
       "      <td>0.00541</td>\n",
       "      <td>0.030627</td>\n",
       "      <td>0.008801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.044510  0.003063  0.002552  0.520000  0.048937  0.012968  0.033831   \n",
       "1  0.044510  0.003063  0.002552  0.813333  0.095403  0.012968  0.055360   \n",
       "2  0.071217  0.008752  0.012345  0.386667  0.014335  0.060519  0.008202   \n",
       "3  0.063684  0.000985  0.000574  0.706667  0.091448  0.002161  0.034856   \n",
       "4  0.044510  0.003063  0.002552  0.973333  0.194266  0.012968  0.049209   \n",
       "\n",
       "         7         8         9         10        11        12        13  \\\n",
       "0  0.265339  0.502890  0.125926  0.017730  0.103448  0.471402  0.236506   \n",
       "1  0.182869  0.576927  0.103704  0.017730  0.206897  0.480830  0.290485   \n",
       "2  0.203984  0.598917  0.130370  0.011426  0.106897  0.505971  0.290485   \n",
       "3  0.163347  0.504170  0.111111  0.017730  0.160920  0.524827  0.168803   \n",
       "4  0.127888  0.533649  0.134815  0.017730  0.077586  0.527970  0.296210   \n",
       "\n",
       "        14       15        16        17  \n",
       "0  0.03681  0.00541  0.074380  0.008801  \n",
       "1  0.03681  0.00541  0.081429  0.008864  \n",
       "2  0.03681  0.00541  0.033544  0.009682  \n",
       "3  0.03681  0.00541  0.067817  0.008801  \n",
       "4  0.03681  0.00541  0.030627  0.008801  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Just checking how our data looking in transformed way\n",
    "\n",
    "checking = pd.DataFrame(transformed_data)\n",
    "checking.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3999, 18) (3999,)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3199, 18) (800, 18) (3199,) (800,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape,y_train.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building  Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put models in dicionary\n",
    "models = {\"Logistic Regression\": LogisticRegression(),\n",
    "          \n",
    "          \"Random Forest\": RandomForestClassifier(),\n",
    "          \"Gaussian Naive Bayes\":GaussianNB(),\n",
    "          \"SVM\":svm.SVC(kernel='linear'),\n",
    "          \"Gradient Boosting\":GradientBoostingClassifier()}\n",
    "\n",
    "# see for example here name = KNN and model =KNeighborsClassifier()\n",
    "\n",
    "# Create function to fit and score model\n",
    "def fit_and_score(models,X_train,X_test,y_train,y_test):\n",
    "    \"\"\"\n",
    "    Fits and evaluate given ml model\n",
    "    models: a dictionary of different scilit-learn machine learning models\n",
    "    x_train : training data\n",
    "    x_test : testing data\n",
    "    \"\"\"\n",
    "    # set up random seed\n",
    "    np.random.seed(42)\n",
    "    # Make a dicitionary to keep models\n",
    "    model_score = {}\n",
    "    # Loop through models\n",
    "    for name, model in models.items():\n",
    "        #Fit the model to data\n",
    "        model.fit(X_train,y_train)\n",
    "        # Evaluate the model and append its score to model_score\n",
    "        model_score[name]=model.score(X_test,y_test)\n",
    "    return model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Logistic Regression': 0.8825,\n",
       " 'Random Forest': 0.88625,\n",
       " 'Gaussian Naive Bayes': 0.8625,\n",
       " 'SVM': 0.88125,\n",
       " 'Gradient Boosting': 0.87875}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_score = fit_and_score(models,x_train,x_test,y_train,y_test)\n",
    "model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87625"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4]),\n",
       " [Text(0, 0, 'Logistic Regression'),\n",
       "  Text(1, 0, 'Random Forest'),\n",
       "  Text(2, 0, 'Gaussian Naive Bayes'),\n",
       "  Text(3, 0, 'SVM'),\n",
       "  Text(4, 0, 'Gradient Boosting')])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_compare=pd.DataFrame(model_score, index=[\"accuracy\"])\n",
    "# model_compare.plot.bar(); # give close bar to each other try it\n",
    "model_compare.T.plot.bar()\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we will do following:\n",
    "\n",
    "-> Hyperparameter Tuning\n",
    "\n",
    "-> Feauture importance\n",
    "\n",
    "-> Confusion matrix\n",
    "\n",
    "-> Cross-Validation\n",
    "\n",
    "-> Precision\n",
    "\n",
    "-> Recall\n",
    "\n",
    "-> F1 score\n",
    "\n",
    "-> Classification report\n",
    "\n",
    "-> ROC curve\n",
    "\n",
    "-> Area under the curve(AUC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypertuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter 'C' for estimator RandomForestClassifier(). Valid parameters are: ['bootstrap', 'ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'max_samples', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Amit\\Desktop\\others\\Data science\\Projects\\ICU_Prediction\\project.ipynb Cell 49\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Amit/Desktop/others/Data%20science/Projects/ICU_Prediction/project.ipynb#Y133sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m gs_log_reg \u001b[39m=\u001b[39m GridSearchCV(model,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Amit/Desktop/others/Data%20science/Projects/ICU_Prediction/project.ipynb#Y133sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m                          param_grid\u001b[39m=\u001b[39mlog_reg_grid,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Amit/Desktop/others/Data%20science/Projects/ICU_Prediction/project.ipynb#Y133sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m                          cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Amit/Desktop/others/Data%20science/Projects/ICU_Prediction/project.ipynb#Y133sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m                          verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Amit/Desktop/others/Data%20science/Projects/ICU_Prediction/project.ipynb#Y133sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Fit the model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Amit/Desktop/others/Data%20science/Projects/ICU_Prediction/project.ipynb#Y133sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m gs_log_reg\u001b[39m.\u001b[39;49mfit(x_train,y_train)\n",
      "File \u001b[1;32mc:\\Users\\Amit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Amit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[0;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    894\u001b[0m     )\n\u001b[0;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[1;32m--> 898\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[0;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Amit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1418\u001b[0m     \u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[1;32mc:\\Users\\Amit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[0;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[0;32m    842\u001b[0m         )\n\u001b[0;32m    843\u001b[0m     )\n\u001b[1;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    847\u001b[0m         clone(base_estimator),\n\u001b[0;32m    848\u001b[0m         X,\n\u001b[0;32m    849\u001b[0m         y,\n\u001b[0;32m    850\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[0;32m    851\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[0;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[0;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[0;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[0;32m    855\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[0;32m    856\u001b[0m     )\n\u001b[0;32m    857\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[0;32m    858\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params), \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, groups))\n\u001b[0;32m    859\u001b[0m     )\n\u001b[0;32m    860\u001b[0m )\n\u001b[0;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    867\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Amit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\Users\\Amit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[0;32m   1865\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\Amit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\Amit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Amit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:720\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    717\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m parameters\u001b[39m.\u001b[39mitems():\n\u001b[0;32m    718\u001b[0m         cloned_parameters[k] \u001b[39m=\u001b[39m clone(v, safe\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m--> 720\u001b[0m     estimator \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39mset_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcloned_parameters)\n\u001b[0;32m    722\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    724\u001b[0m X_train, y_train \u001b[39m=\u001b[39m _safe_split(estimator, X, y, train)\n",
      "File \u001b[1;32mc:\\Users\\Amit\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:229\u001b[0m, in \u001b[0;36mBaseEstimator.set_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m    227\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m valid_params:\n\u001b[0;32m    228\u001b[0m     local_valid_params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_param_names()\n\u001b[1;32m--> 229\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    230\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid parameter \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m!r}\u001b[39;00m\u001b[39m for estimator \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    231\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mValid parameters are: \u001b[39m\u001b[39m{\u001b[39;00mlocal_valid_params\u001b[39m!r}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m     )\n\u001b[0;32m    234\u001b[0m \u001b[39mif\u001b[39;00m delim:\n\u001b[0;32m    235\u001b[0m     nested_params[key][sub_key] \u001b[39m=\u001b[39m value\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter 'C' for estimator RandomForestClassifier(). Valid parameters are: ['bootstrap', 'ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'max_samples', 'min_impurity_decrease', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start']."
     ]
    }
   ],
   "source": [
    "#  Different hyperparameters for our LogisticRegression Model\n",
    "np.random.seed(42)\n",
    "model = RandomForestClassifier()\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30]\n",
    "}\n",
    "# here taking param_grid value anything as later on we will find it best param\n",
    "\n",
    "# Setup grid hyperparameter search for LogisticRegression\n",
    "gs_log_reg = GridSearchCV(model,\n",
    "                         param_grid=log_reg_grid,\n",
    "                         cv=5,\n",
    "                         verbose=True)\n",
    "\n",
    "# Fit the model\n",
    "gs_log_reg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
